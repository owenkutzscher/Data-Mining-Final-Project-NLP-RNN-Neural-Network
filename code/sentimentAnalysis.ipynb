{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "# After doing some research, we will want to use TensorFlow, prob Keras (a deep\n",
    "# learning API written on top of TensorFlow, it's currently being used\n",
    "# in the LHC (Large Hadron Collider)).\n",
    "\n",
    "# We will be classifying text with BERT:\n",
    "# https://www.tensorflow.org/text/tutorials/classify_text_with_bert\n",
    "\n",
    "# NOTE: as of 10/19/23 tensorflow will not run on windowns\n",
    "# I recomend running this through jupyterlab on a linux kernal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-text==2.13.* in /Applications/anaconda3/lib/python3.8/site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-hub>=0.8.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow-text==2.13.*) (0.15.0)\n",
      "Requirement already satisfied: tensorflow<2.14,>=2.13.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow-text==2.13.*) (2.13.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (2.10.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (3.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (1.12.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (3.20.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (2.13.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (0.2.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (1.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (0.34.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (1.6.3)\n",
      "Requirement already satisfied: packaging in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (23.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (2.3.0)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (23.5.26)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (1.23.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (4.5.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (1.59.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (2.13.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (0.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (1.15.0)\n",
      "Requirement already satisfied: setuptools in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (52.0.0.post20210125)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Applications/anaconda3/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (0.36.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (3.5)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (0.7.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (2.23.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (2.25.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Applications/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Applications/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Applications/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (0.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Applications/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Applications/anaconda3/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (6.8.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Applications/anaconda3/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (3.4.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Applications/anaconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (0.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Applications/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Applications/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Applications/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Applications/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (2020.12.5)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Applications/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "# A dependency of the preprocessing for BERT inputs\n",
    "!pip install -U \"tensorflow-text==2.13.*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf-models-official==2.13.* in /Applications/anaconda3/lib/python3.8/site-packages (2.13.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Applications/anaconda3/lib/python3.8/site-packages (from tf-models-official==2.13.*) (1.10.1)\n",
      "Requirement already satisfied: oauth2client in /Applications/anaconda3/lib/python3.8/site-packages (from tf-models-official==2.13.*) (4.1.3)\n",
      "Requirement already satisfied: immutabledict in /Applications/anaconda3/lib/python3.8/site-packages (from tf-models-official==2.13.*) (3.0.0)\n",
      "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /Applications/anaconda3/lib/python3.8/site-packages (from tf-models-official==2.13.*) (0.7.5)\n",
      "Requirement already satisfied: tensorflow~=2.13.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tf-models-official==2.13.*) (2.13.1)\n",
      "Requirement already satisfied: gin-config in /Applications/anaconda3/lib/python3.8/site-packages (from tf-models-official==2.13.*) (0.5.0)\n",
      "Requirement already satisfied: sentencepiece in /Applications/anaconda3/lib/python3.8/site-packages (from tf-models-official==2.13.*) (0.1.99)\n",
      "Requirement already satisfied: tensorflow-hub>=0.6.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tf-models-official==2.13.*) (0.15.0)\n",
      "Requirement already satisfied: tensorflow-text~=2.13.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tf-models-official==2.13.*) (2.13.0)\n",
      "Requirement already satisfied: Cython in /Applications/anaconda3/lib/python3.8/site-packages (from tf-models-official==2.13.*) (0.29.23)\n",
      "Requirement already satisfied: matplotlib in /Applications/anaconda3/lib/python3.8/site-packages (from tf-models-official==2.13.*) (3.3.4)\n",
      "Requirement already satisfied: numpy>=1.20 in /Applications/anaconda3/lib/python3.8/site-packages (from tf-models-official==2.13.*) (1.23.0)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tf-models-official==2.13.*) (6.0.1)\n",
      "Requirement already satisfied: seqeval in /Applications/anaconda3/lib/python3.8/site-packages (from tf-models-official==2.13.*) (1.2.2)\n",
      "Requirement already satisfied: Pillow in /Applications/anaconda3/lib/python3.8/site-packages (from tf-models-official==2.13.*) (8.2.0)\n",
      "Requirement already satisfied: pycocotools in /Applications/anaconda3/lib/python3.8/site-packages (from tf-models-official==2.13.*) (2.0.7)\n",
      "Requirement already satisfied: py-cpuinfo>=3.3.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tf-models-official==2.13.*) (9.0.0)\n",
      "Requirement already satisfied: sacrebleu in /Applications/anaconda3/lib/python3.8/site-packages (from tf-models-official==2.13.*) (2.3.1)\n",
      "Requirement already satisfied: opencv-python-headless in /Applications/anaconda3/lib/python3.8/site-packages (from tf-models-official==2.13.*) (4.8.1.78)\n",
      "Requirement already satisfied: pandas>=0.22.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tf-models-official==2.13.*) (1.2.4)\n",
      "Requirement already satisfied: psutil>=5.4.3 in /Applications/anaconda3/lib/python3.8/site-packages (from tf-models-official==2.13.*) (5.8.0)\n",
      "Requirement already satisfied: tensorflow-datasets in /Applications/anaconda3/lib/python3.8/site-packages (from tf-models-official==2.13.*) (4.9.2)\n",
      "Requirement already satisfied: tf-slim>=1.1.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tf-models-official==2.13.*) (1.1.0)\n",
      "Requirement already satisfied: google-api-python-client>=1.6.7 in /Applications/anaconda3/lib/python3.8/site-packages (from tf-models-official==2.13.*) (2.104.0)\n",
      "Requirement already satisfied: kaggle>=1.3.9 in /Applications/anaconda3/lib/python3.8/site-packages (from tf-models-official==2.13.*) (1.5.16)\n",
      "Requirement already satisfied: six in /Applications/anaconda3/lib/python3.8/site-packages (from tf-models-official==2.13.*) (1.15.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /Applications/anaconda3/lib/python3.8/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.13.*) (2.12.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /Applications/anaconda3/lib/python3.8/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.13.*) (0.1.1)\n",
      "Requirement already satisfied: google-auth<3.0.0.dev0,>=1.19.0 in /Applications/anaconda3/lib/python3.8/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.13.*) (2.23.3)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Applications/anaconda3/lib/python3.8/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.13.*) (4.1.1)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.15.0 in /Applications/anaconda3/lib/python3.8/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.13.*) (0.22.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /Applications/anaconda3/lib/python3.8/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official==2.13.*) (2.25.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /Applications/anaconda3/lib/python3.8/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official==2.13.*) (1.61.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /Applications/anaconda3/lib/python3.8/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official==2.13.*) (3.20.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Applications/anaconda3/lib/python3.8/site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official==2.13.*) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Applications/anaconda3/lib/python3.8/site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official==2.13.*) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Applications/anaconda3/lib/python3.8/site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official==2.13.*) (0.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Applications/anaconda3/lib/python3.8/site-packages (from httplib2<1.dev0,>=0.15.0->google-api-python-client>=1.6.7->tf-models-official==2.13.*) (2.4.7)\n",
      "Requirement already satisfied: certifi in /Applications/anaconda3/lib/python3.8/site-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (2020.12.5)\n",
      "Requirement already satisfied: python-slugify in /Applications/anaconda3/lib/python3.8/site-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (8.0.1)\n",
      "Requirement already satisfied: bleach in /Applications/anaconda3/lib/python3.8/site-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (3.3.0)\n",
      "Requirement already satisfied: urllib3 in /Applications/anaconda3/lib/python3.8/site-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (1.26.4)\n",
      "Requirement already satisfied: tqdm in /Applications/anaconda3/lib/python3.8/site-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (4.59.0)\n",
      "Requirement already satisfied: python-dateutil in /Applications/anaconda3/lib/python3.8/site-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Applications/anaconda3/lib/python3.8/site-packages (from pandas>=0.22.0->tf-models-official==2.13.*) (2021.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Applications/anaconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official==2.13.*) (0.5.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Applications/anaconda3/lib/python3.8/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official==2.13.*) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Applications/anaconda3/lib/python3.8/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official==2.13.*) (2.10)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (2.10.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (2.3.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (1.59.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (2.13.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (2.13.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (1.12.1)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (23.5.26)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (0.2.0)\n",
      "Requirement already satisfied: setuptools in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (52.0.0.post20210125)\n",
      "Requirement already satisfied: packaging in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (23.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (1.4.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (4.5.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (2.13.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (1.6.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (16.0.6)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (0.34.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Applications/anaconda3/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow~=2.13.0->tf-models-official==2.13.*) (0.36.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (3.5)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (1.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Applications/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Applications/anaconda3/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (6.8.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Applications/anaconda3/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (3.4.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Applications/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (3.2.2)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official==2.13.*) (0.1.8)\n",
      "Requirement already satisfied: webencodings in /Applications/anaconda3/lib/python3.8/site-packages (from bleach->kaggle>=1.3.9->tf-models-official==2.13.*) (0.5.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Applications/anaconda3/lib/python3.8/site-packages (from matplotlib->tf-models-official==2.13.*) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Applications/anaconda3/lib/python3.8/site-packages (from matplotlib->tf-models-official==2.13.*) (1.3.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /Applications/anaconda3/lib/python3.8/site-packages (from python-slugify->kaggle>=1.3.9->tf-models-official==2.13.*) (1.3)\n",
      "Requirement already satisfied: regex in /Applications/anaconda3/lib/python3.8/site-packages (from sacrebleu->tf-models-official==2.13.*) (2021.4.4)\n",
      "Requirement already satisfied: colorama in /Applications/anaconda3/lib/python3.8/site-packages (from sacrebleu->tf-models-official==2.13.*) (0.4.4)\n",
      "Requirement already satisfied: lxml in /Applications/anaconda3/lib/python3.8/site-packages (from sacrebleu->tf-models-official==2.13.*) (4.6.3)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /Applications/anaconda3/lib/python3.8/site-packages (from sacrebleu->tf-models-official==2.13.*) (0.9.0)\n",
      "Requirement already satisfied: portalocker in /Applications/anaconda3/lib/python3.8/site-packages (from sacrebleu->tf-models-official==2.13.*) (2.8.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /Applications/anaconda3/lib/python3.8/site-packages (from seqeval->tf-models-official==2.13.*) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Applications/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.13.*) (2.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Applications/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.13.*) (1.3.2)\n",
      "Requirement already satisfied: click in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow-datasets->tf-models-official==2.13.*) (7.1.2)\n",
      "Requirement already satisfied: importlib-resources in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow-datasets->tf-models-official==2.13.*) (6.0.1)\n",
      "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow-datasets->tf-models-official==2.13.*) (1.3.0)\n",
      "Requirement already satisfied: array-record in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow-datasets->tf-models-official==2.13.*) (0.4.0)\n",
      "Requirement already satisfied: toml in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow-datasets->tf-models-official==2.13.*) (0.10.2)\n",
      "Requirement already satisfied: tensorflow-metadata in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow-datasets->tf-models-official==2.13.*) (1.14.0)\n",
      "Requirement already satisfied: promise in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow-datasets->tf-models-official==2.13.*) (2.3)\n"
     ]
    }
   ],
   "source": [
    "# Use use the AdamW optimizer from https://github.com/tensorflow/models.\n",
    "!pip install \"tf-models-official==2.13.*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nesisary libraries\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text \n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "\n",
    "import keras\n",
    "import keras.utils\n",
    "import keras.layers\n",
    "import keras.models\n",
    "import keras.optimizers\n",
    "from keras import utils as np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dataset directory structure\n",
    "# This will make it easy to organize and accesss our data in our directory structure\n",
    "\n",
    "\n",
    "dataset_dir = '../data/amazon_reviews'\n",
    "os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "# Make it easy to access 'train' and 'test' directories inside the dataset directory\n",
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "test_dir = os.path.join(dataset_dir, 'test')\n",
    "\n",
    "# This will build the 'train' and 'test' directories if they haven't been built yet\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# This will build the folders 1, 2, 3, 4, 5 inside both the train and test directories\n",
    "one_dir_train = os.path.join(train_dir, '1')\n",
    "two_dir_train = os.path.join(train_dir, '2')\n",
    "three_dir_train = os.path.join(train_dir, '3')\n",
    "four_dir_train = os.path.join(train_dir, '4')\n",
    "five_dir_train = os.path.join(train_dir, '5')\n",
    "os.makedirs(one_dir_train, exist_ok=True)\n",
    "os.makedirs(two_dir_train, exist_ok=True)\n",
    "os.makedirs(three_dir_train, exist_ok=True)\n",
    "os.makedirs(four_dir_train, exist_ok=True)\n",
    "os.makedirs(five_dir_train, exist_ok=True)\n",
    "one_dir_test = os.path.join(test_dir, '1')\n",
    "two_dir_test = os.path.join(test_dir, '2')\n",
    "three_dir_test = os.path.join(test_dir, '3')\n",
    "four_dir_test = os.path.join(test_dir, '4')\n",
    "five_dir_test = os.path.join(test_dir, '5')\n",
    "os.makedirs(one_dir_test, exist_ok=True)\n",
    "os.makedirs(two_dir_test, exist_ok=True)\n",
    "os.makedirs(three_dir_test, exist_ok=True)\n",
    "os.makedirs(four_dir_test, exist_ok=True)\n",
    "os.makedirs(five_dir_test, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I ordered this thinking it would be a good way...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I purchased this even after a few other review...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>I wasn't a huge fan of the taste of Crunchy Nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>I have been drinking Zico coconut water for so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>I dont know what all the good reviews were for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score                                               Text\n",
       "0      1  I ordered this thinking it would be a good way...\n",
       "1      1  I purchased this even after a few other review...\n",
       "2      1  I wasn't a huge fan of the taste of Crunchy Nu...\n",
       "3      1  I have been drinking Zico coconut water for so...\n",
       "4      1  I dont know what all the good reviews were for..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading the dataset\n",
    "# IMPORTANT!!!!\n",
    "# In order to run this project drop in the .csv data set (called: \"Reviews\") into the \"data\" folder\n",
    "# You can find the data set here:\n",
    "# https://www.google.com/url?q=https://www.kaggle.com/datasets/arhamrumi/amazon-product-reviews&sa=D&source=docs&ust=1695764896933142&usg=AOvVaw1WeATDdUdlTItgNGGldkRF\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df_extra_params = pd.read_csv(\"../data/Reviews.csv\")\n",
    "\n",
    "# Select only the \"Score\" and \"Text\" columns\n",
    "df_unbalanced = df_extra_params[[\"Score\", \"Text\"]]\n",
    "\n",
    "# Determine minimum number of reviews for any score\n",
    "min_reviews = df_unbalanced['Score'].value_counts().min()\n",
    "\n",
    "# Make sure each review score 1-5 has the same number of reviews\n",
    "df = df_unbalanced.groupby('Score').apply(lambda x: x.sample(min_reviews)).reset_index(drop=True)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying the data into our directory structure\n",
    "# We will seperate the data into the train and test folders\n",
    "# Inside the train and test folders we have folders 1, 2, 3, 4, 5\n",
    "# This corresponds to the \"Score\" of the review\n",
    "# Split with 50/50 ratio, randomly divided \n",
    "# Also take note of the \"sample_fraction\" variable, this is used to\n",
    "# reduce the ammount of data we will feed to BERT. This will help us\n",
    "# reduce training time when expiramenting with BERT.\n",
    "\n",
    "\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Path to the base folder\n",
    "base_folder = '../data/amazon_reviews'\n",
    "\n",
    "# Delete existing reviews from train and test folders\n",
    "for score_folder in ['1', '2', '3', '4', '5']:\n",
    "    train_folder_path = f'{base_folder}/train/{score_folder}'\n",
    "    test_folder_path = f'{base_folder}/test/{score_folder}'\n",
    "\n",
    "    shutil.rmtree(train_folder_path, ignore_errors=True)\n",
    "    shutil.rmtree(test_folder_path, ignore_errors=True)\n",
    "\n",
    "    # Recreate the train and test folders\n",
    "    os.makedirs(train_folder_path)\n",
    "    os.makedirs(test_folder_path)\n",
    "\n",
    "\n",
    "\n",
    "# Determine the fraction for sampling (1/40th of the entire dataset)\n",
    "# Tip: for extra speedy runtimes, make this 1/40\n",
    "sample_fraction = 1/80\n",
    "\n",
    "# Separate all data into 5 dfs for scores 1-5 respectively\n",
    "df_1 = df.loc[(df[\"Score\"] == 1)]\n",
    "df_2 = df.loc[(df[\"Score\"] == 2)]\n",
    "df_3 = df.loc[(df[\"Score\"] == 3)]\n",
    "df_4 = df.loc[(df[\"Score\"] == 4)]\n",
    "df_5 = df.loc[(df[\"Score\"] == 5)]\n",
    "\n",
    "# Splitting data into test and train folders with a 50/50 ratio\n",
    "df_1_train = df_1.sample(frac=sample_fraction, replace=False, random_state=1)\n",
    "df_1_test = df_1[~df_1.isin(df_1_train)].dropna(how='all')\n",
    "\n",
    "df_2_train = df_2.sample(frac=sample_fraction, replace=False, random_state=1)\n",
    "df_2_test = df_2[~df_2.isin(df_2_train)].dropna(how='all')\n",
    "\n",
    "df_3_train = df_3.sample(frac=sample_fraction, replace=False, random_state=1)\n",
    "df_3_test = df_3[~df_3.isin(df_3_train)].dropna(how='all')\n",
    "\n",
    "df_4_train = df_4.sample(frac=sample_fraction, replace=False, random_state=1)\n",
    "df_4_test = df_4[~df_4.isin(df_4_train)].dropna(how='all')\n",
    "\n",
    "df_5_train = df_5.sample(frac=sample_fraction, replace=False, random_state=1)\n",
    "df_5_test = df_5[~df_5.isin(df_5_train)].dropna(how='all')\n",
    "\n",
    "# Converting df values into txt files, putting them in the correct folders\n",
    "def save_reviews_to_folder(df, folder_path, score):\n",
    "    for index, row in df.iterrows():\n",
    "        path = f'{folder_path}/review{index}.txt'\n",
    "        with open(path, 'a') as f:\n",
    "            txt_in = row[\"Text\"]\n",
    "            f.write(txt_in)\n",
    "\n",
    "# Define folder paths\n",
    "train_folder_base = '../data/amazon_reviews/train'\n",
    "test_folder_base = '../data/amazon_reviews/test'\n",
    "\n",
    "# Save reviews to train and test folders\n",
    "save_reviews_to_folder(df_1_train, f'{train_folder_base}/1', 1)\n",
    "save_reviews_to_folder(df_1_test, f'{test_folder_base}/1', 1)\n",
    "\n",
    "save_reviews_to_folder(df_2_train, f'{train_folder_base}/2', 2)\n",
    "save_reviews_to_folder(df_2_test, f'{test_folder_base}/2', 2)\n",
    "\n",
    "save_reviews_to_folder(df_3_train, f'{train_folder_base}/3', 3)\n",
    "save_reviews_to_folder(df_3_test, f'{test_folder_base}/3', 3)\n",
    "\n",
    "save_reviews_to_folder(df_4_train, f'{train_folder_base}/4', 4)\n",
    "save_reviews_to_folder(df_4_test, f'{test_folder_base}/4', 4)\n",
    "\n",
    "save_reviews_to_folder(df_5_train, f'{train_folder_base}/5', 5)\n",
    "save_reviews_to_folder(df_5_test, f'{test_folder_base}/5', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372\n",
      "372\n"
     ]
    }
   ],
   "source": [
    "# Lets do a quick sanity check to make sure our reviews are \n",
    "# evenly distributed in our directory\n",
    "\n",
    "import os\n",
    "\n",
    "folder_path = '../data/amazon_reviews/train/4'\n",
    "\n",
    "# Get the list of items in the folder\n",
    "items = os.listdir(folder_path)\n",
    "\n",
    "# Print the number of items in the folder\n",
    "print(len(items))\n",
    "\n",
    "\n",
    "# repeat but with a different reviews folder\n",
    "folder_path = '../data/amazon_reviews/train/3'\n",
    "\n",
    "items = os.listdir(folder_path)\n",
    "\n",
    "print(len(items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1860 files belonging to 5 classes.\n",
      "Using 1488 files for training.\n",
      "Found 1860 files belonging to 5 classes.\n",
      "Using 372 files for validation.\n",
      "Found 146985 files belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# Now we will use the text_dataset_from_directory utility to create a labeled tf.data.Dataset.\n",
    "# Let's create a validation set using an 80:20 split of the training data by\n",
    "# using the validation_split argument below.\n",
    "\n",
    "# Note: When using the validation_split and subset arguments\n",
    "# make sure to either specify a random seed, or to pass shuffle=False, \n",
    "# so that the validation and training splits have no overlap.\n",
    "\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "\n",
    "raw_train_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    '../data/amazon_reviews/train',\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    labels='inferred',\n",
    "    subset='training',\n",
    "    seed=seed,\n",
    "    label_mode='int')\n",
    "\n",
    "class_names = raw_train_ds.class_names\n",
    "train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "val_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    '../data/amazon_reviews/train',\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    labels='inferred',\n",
    "    subset='validation',\n",
    "    seed=seed,\n",
    "    label_mode='int')\n",
    "\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "test_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    '../data/amazon_reviews/test',\n",
    "    batch_size=batch_size,\n",
    "    labels='inferred',\n",
    "    label_mode='int')\n",
    "\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(None,), dtype=tf.int32, name=None)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.element_spec[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    File \"<ipython-input-298-626d90235200>\", line 18, in _map_func  *\n        if label.numpy()[i]==0:\n\n    AttributeError: 'Tensor' object has no attribute 'numpy'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-298-626d90235200>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mtrain_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_map_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;31m# test_ds = test_ds.map(_map_func)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# val_ds = val_ds.map(_map_func)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2276\u001b[0m     \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2277\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmap_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2278\u001b[0;31m     return map_op._map_v2(\n\u001b[0m\u001b[1;32m   2279\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2280\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/data/ops/map_op.py\u001b[0m in \u001b[0;36m_map_v2\u001b[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m     35\u001b[0m       warnings.warn(\"The `deterministic` argument has no effect unless the \"\n\u001b[1;32m     36\u001b[0m                     \"`num_parallel_calls` argument is specified.\")\n\u001b[0;32m---> 37\u001b[0;31m     return _MapDataset(\n\u001b[0m\u001b[1;32m     38\u001b[0m         input_dataset, map_func, preserve_cardinality=True, name=name)\n\u001b[1;32m     39\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/data/ops/map_op.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_inter_op_parallelism\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_inter_op_parallelism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preserve_cardinality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     self._map_func = structured_function.StructuredFunctionWrapper(\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mfn_factory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefun_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;31m# There is no graph to add in eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0madd_to_graph\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1187\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;31m# Implements GenericFunction.get_concrete_function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m     \u001b[0mconcrete\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concrete_function_garbage_collected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m     \u001b[0mconcrete\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcrete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1167\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m         \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_uninitialized_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[0;31m# Force the definition of the function for these arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m     self._concrete_variable_creation_fn = (\n\u001b[0;32m--> 694\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m    \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m         ._get_concrete_function_internal_garbage_collected(\n\u001b[1;32m    696\u001b[0m             *args, **kwds))\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;34m\"\"\"Returns a concrete function which cleans up its graph function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m       \u001b[0mconcrete_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcrete_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_maybe_define_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_concrete_function_internal_garbage_collected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplaceholder_bound_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m           concrete_function = self._create_concrete_function(\n\u001b[0m\u001b[1;32m    399\u001b[0m               args, kwargs, func_graph)\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_create_concrete_function\u001b[0;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     concrete_function = monomorphic_function.ConcreteFunction(\n\u001b[0;32m--> 305\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    306\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1055\u001b[0;31m     \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m     \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    236\u001b[0m       \u001b[0;31m# Note: wrapper_helper will apply autograph based on context.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    166\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_should_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariable_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_variables_to_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_should_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    691\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/rz/n56_zwz96bv_fylr1q47qjgh0000gn/T/__autograph_generated_file4xsvtw9a.py\u001b[0m in \u001b[0;36mtf___map_func\u001b[0;34m(text, labels)\u001b[0m\n\u001b[1;32m     67\u001b[0m                     \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_body_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melse_body_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'iterate_names'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'label'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/operators/control_flow.py\u001b[0m in \u001b[0;36mfor_stmt\u001b[0;34m(iter_, extra_test, body, get_state, set_state, symbol_names, opts)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[0mfor_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tf_distributed_iterable_for_stmt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m   \u001b[0mfor_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/operators/control_flow.py\u001b[0m in \u001b[0;36m_known_len_tf_for_stmt\u001b[0;34m(iter_, extra_test, body, get_state, set_state, symbol_names, opts)\u001b[0m\n\u001b[1;32m    549\u001b[0m   \u001b[0m_add_max_iterations_hint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m   _tf_while_stmt(\n\u001b[0m\u001b[1;32m    552\u001b[0m       \u001b[0maug_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0maug_body\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/operators/control_flow.py\u001b[0m in \u001b[0;36m_tf_while_stmt\u001b[0;34m(test, body, get_state, set_state, symbol_names, opts)\u001b[0m\n\u001b[1;32m   1203\u001b[0m     \u001b[0maug_init_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_vars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1205\u001b[0;31m   final_loop_vars = while_loop.while_loop(aug_test, aug_body, aug_init_vars,\n\u001b[0m\u001b[1;32m   1206\u001b[0m                                           **while_loop_opts)\n\u001b[1;32m   1207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/while_loop.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m    449\u001b[0m   if (util.EnableControlFlowV2(ops.get_default_graph()) and\n\u001b[1;32m    450\u001b[0m       not executing_eagerly):\n\u001b[0;32m--> 451\u001b[0;31m     return while_v2.while_loop(\n\u001b[0m\u001b[1;32m    452\u001b[0m         \u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, maximum_iterations, name, return_same_structure, back_prop)\u001b[0m\n\u001b[1;32m    201\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mloop_counter\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaximum_iterations_arg\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m     body_graph = func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0mbody_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mwrapped_body\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1055\u001b[0;31m     \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m     \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36mwrapped_body\u001b[0;34m(loop_counter, maximum_iterations_arg, *args)\u001b[0m\n\u001b[1;32m    179\u001b[0m       \u001b[0;31m# converts flows in `args` to TensorArrays and packs it into the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m       \u001b[0;31m# structure of `loop_vars_signature`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m       outputs = body(\n\u001b[0m\u001b[1;32m    182\u001b[0m           *_pack_sequence_as(loop_vars_signature, flat_orig_loop_vars, args))\n\u001b[1;32m    183\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/operators/control_flow.py\u001b[0m in \u001b[0;36maug_body\u001b[0;34m(*loop_vars)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m     \u001b[0mset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m     \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m     \u001b[0mnew_loop_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m     verify_tf_loop_vars(\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/operators/control_flow.py\u001b[0m in \u001b[0;36maug_body\u001b[0;34m()\u001b[0m\n\u001b[1;32m    538\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0maug_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[0;32mnonlocal\u001b[0m \u001b[0miterate_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m     \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterate_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m     \u001b[0miterate_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/rz/n56_zwz96bv_fylr1q47qjgh0000gn/T/__autograph_generated_file4xsvtw9a.py\u001b[0m in \u001b[0;36mloop_body\u001b[0;34m(itr)\u001b[0m\n\u001b[1;32m     65\u001b[0m                             \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_body_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melse_body_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                         \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_body_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melse_body_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                     \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_body_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melse_body_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m                 \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'iterate_names'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'label'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0mnp_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_numpy_behavior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m       \"\"\")\n\u001b[0;32m--> 430\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: in user code:\n\n    File \"<ipython-input-298-626d90235200>\", line 18, in _map_func  *\n        if label.numpy()[i]==0:\n\n    AttributeError: 'Tensor' object has no attribute 'numpy'\n"
     ]
    }
   ],
   "source": [
    "def _map_func(text, labels):\n",
    "    # i=0\n",
    "    # labels_enc = tf.TensorArray(tf.float32, size=0, dynamic_size=True,clear_after_read=False)\n",
    "    # for text_batch, label_batch in train_ds.take(1):\n",
    "    #     label = label_batch.numpy()[i]\n",
    "    #     if label==0:\n",
    "    #         label = 1\n",
    "    #     elif label==1:\n",
    "    #         label = 2\n",
    "    #     elif label==2:\n",
    "    #         label = 3\n",
    "    #     elif label==3:\n",
    "    #         label = 4\n",
    "    #     else: \n",
    "    #         label = 5\n",
    "    #     print(f'Label : {label} ({class_names[label]})')\n",
    "    for label in labels:\n",
    "        if label.numpy()[i]==0:\n",
    "            label.numpy()[i] = 1\n",
    "        elif label.numpy()[i]==1:\n",
    "            label.numpy()[i] = 2\n",
    "        elif label.numpy()[i]==2:\n",
    "            label.numpy()[i] = 3\n",
    "        elif label.numpy()[i]==3:\n",
    "            label.numpy()[i] = 4\n",
    "        else: \n",
    "            label.numpy()[i] = 5\n",
    "        # label = tf.one_hot(label, 5, name='label', axis=-1)\n",
    "        # labels_enc.write(i, label)\n",
    "        # i+=1\n",
    "\n",
    "    return text, labels\n",
    "    \n",
    "train_ds = train_ds.map(_map_func)\n",
    "# test_ds = test_ds.map(_map_func)\n",
    "# val_ds = val_ds.map(_map_func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: b'I ordered the \"Frontier Brand\", but did not recieve that brand.  The packaging was totally different and shipping was outrageous.  I did not realize that I had ordered from a 3rd party seller.  The product was fine, but I rated it a 2 because I feel like this is false advertising.  You should get the brand that you ordered.  I am not sure if it is Amazon\\'s fault or the 3rd party seller for selling the product under a false name.  Anyway, if you want to order the frontier brand, make sure you order directly from Amazon...just b/c you order it from the Amazon website does not mean that you are ordering it from Amazon, so BEWARE!'\n",
      "Label : 1 (2)\n",
      "Review: b'These fruit snacks are awesome and wanted to ship some down to my daughter so came to my trusty Amazaon Subscribe - When I saw the price, I started scanning because I thought this must be for 3-4 boxes at least - wrong!!!  I just bought 4 boxes at Menards and they were $6 each - I can ship those to my daughter for less than what one of these boxes on Amazon would cost.'\n",
      "Label : 1 (2)\n",
      "Review: b\"My 18 yr old son thinks Taco Bell is ok and said this sauce is very much like what you get when you go to Taco Bell. My wife thought it too spicy, but she is not a fan of spicy foods. I thought it was ok - a bit like 1,000 island dressing with a slight kick - not quite as sweet. It also reminded me a bit of the dip you get when you go to Outback and get their bloomin onions.<br /><br />It did not 'wow' any of us, we'll use it until it is gone, but no plans to buy more. Since other reviewers have gone to great lengths to list the ingredients, nutitional information, etc I will not duplicate their work.<br /><br />This is glueten free, so that is a +\"\n",
      "Label : 2 (3)\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in train_ds.take(1):\n",
    "  for i in range(3):\n",
    "    print(f'Review: {text_batch.numpy()[i]}')\n",
    "    label = label_batch.numpy()[i]\n",
    "    print(f'Label : {label} ({class_names[label]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(32,), dtype=string, numpy=\n",
      "array([b\"Dark Magic doesn't taste overwhelming.  No burnt flavor. Tolerable straight black. I add creamer and one packet of stevia and it still holds it's bold flavor, just a little milder.  Nutty taste.\",\n",
      "       b\"Rescue Remedy is a terrific product.  It truly has calmed my Labador Retriever mix.  I have bought the product from Home Naturals Inc. three times.  They had the product in stock and it quickly shipped in November and December, 2009.  I purchased a 3-pack from them in March 2010.  The order didn't arrive and Home Naturals told me it got lost in the mail.  The communication with Home Naturals was great and they said they would send out a replacement 3-pack right away, which they did.  When the package arrived, it contained only 1 bottle (not three).  I asked for and they granted a refund for the 2 missing bottles.  Since then, they have sent a replacement 3-pack, for free.\",\n",
      "       b'Our little man was extremely fussy - our Ped\\'s Dr. thought it might be a milk & soy allergy, & recommended this formula. Within a few days, the hours upon hours of fussiness ended & turned into 20 minutes here & there.  He got so good we thought, \"maybe he\\'s not really allergic to soy\" - so we tried a dfferent (and less expensive forumla) - mistake - we\\'re back on the Alimentum & the little man is back to his low state of fussiness.  He\\'s also put on quite a bit of weight, seems generally less constipated, & has less spit up.  I think we\\'re hooked.',\n",
      "       b'Product is delicious and the tubs arrived on time.  I used to use a product by another name but this one tastes the same.  I was very pleased to find this brand.',\n",
      "       b'Beware...the \"Crunch!\"  is for real.  So real, I broke a tooth eating the stuff.  It seemed good, maybe I received an over cooked batch.  Too scared to try it again.  It has ended up being the most expensive cereal I ever purchased:(',\n",
      "       b\"The product description says only:<br />Product Description<br />Save on Annie Chun`s Spicy Chicken noodles (12/4.7 OZ?. Made from all natural or organic ingredients. Enjoy! Please check the manufacturers label for ingredients before use.<br /><br />Most of us want to check the manufacturer's label before buying. Here is what I found on the AC website:<br />NOODLES: WATER, WHEAT FLOUR, TAPIOCA STARCH, SALT, WHEAT GLUTEN, LACTIC ACID, ACETIC ACID, RIBOFLAVIN (VITAMIN B2), SOUP BASE: ORGANIC CHICKEN BASE (ORGANIC CHICKEN MEAT AND NATURAL JUICES, ORGANIC MALTODEXTRIN, ORGANIC CHIKEN STOCK, ORGANIC CANE SUGAR, ORGANIC CHICKEN FAT, ORGANIC POTATO STARCH, NATURAL FLAVOR, ORGANIC ONION*, ORGANIC GARLIC*, ORGANIC TUMERIC), SEA SALT, RED CHILI GARLIC PUREE (FRESH CHILE PEPPER, DISTILLED VINEGAR, GARLIC, SALT), GINGER (GINGER, WATER, CITRIC ACID), MIREPOIX (MALTODEXTRIN, ONION, SALT, SUGAR, YEAST EXTRACT, CORN SALAD OIL, CARROT, CELERY, SPICES, RED WINE), WATER, YEAST EXTRACT, SHIITAKE MUSTHROOM POWDER (SHIITAKE MUSHROOM, DEXTRIN, SALT, WHEAT FLOUR, YEAST EXTRACT). *DEHYDRATED<br /><br />PRODUCT MANUFACTURED IN A FACILITY THAT USES, SOY, MILK, PEANUTS, TREE NUTS, EGGS, FISH AND SHELLFISH.  STORE IN A COOL DRY PLACE. AVOID DIRECT SUNLIGHT.<br /><br />PRODUCT OF THE USA\",\n",
      "       b'Good tasting filling. Not too thick with corn syrup. But I am not used to watching for pits when I buy canned cherry pie filling. I probably wil not buy again because of the pits.',\n",
      "       b'We were able to try the raisin cookie and it was yummy! Both my kids love rasins and they really enjoyed this cookie. So much healthier then chocolate! Will be buying lots more.',\n",
      "       b\"My baby is ready for some new foods in her diet so I decided to give Gerber 2nd Foods a try. Gerber 2nds is vastly different from the other brands of 2nd baby foods that we have tried. The other brands seem to be similar in consistency. There is really no difference in the consistency of Gerber 1sts and 2nds. The difference is that 2nds includes turkey, chicken and beef and 1sts are all fruits and veggies. My baby did not find Gerber 2nds appetizing. The color and odor of the chicken is also nothing like actual chicken. I placed the lid back on the jar and refrigerated the jar since I was hoping to try it with her for another meal. The next day I got the Gerber 2nds jar from the fridge and reheated it. When it was reheated the food was so runny that she could have drunk it from a bottle. The consistency does not keep from one day to the next. If you're looking for a baby food with chicken, turkey, or beef then I would recommend that you try Beech Nut Stage 1. My baby loved the Beech Nut turkey, chicken, and beef. The only problem is that the major grocery stores in my area do not sell Beech Nut. Next trip that I make I plan to stock up on the Beech Nut!\",\n",
      "       b\"Yes, because it does taste like lucuma in its original form. No, because it is quite expensive for what one gets. Let's say you decide to make an ice cream and use conventional methods, it will take most of the package. Lucuma has always been a truly unique kind of fruit, plus its added benefits in terms of health, you can make use of it in several ways. Smoothies, ice cream, pies, icings etc. From what I have read it maintains well in dry form but perhaps looses some of its intensity in flavor, but from what I tried not very much. 3.5 Stars.\",\n",
      "       b'I Thought I was order mocha not hazelnut!  Do not care for hazelnut and because it is a groccery Item you can not return it so be very careful on ordering!  The french vanilla is very good and I am sure if you like hazelnut it is also very good!',\n",
      "       b\"I've submitted this review once before, and it appears to have been deleted.  Even odder, the description of the product has been changed to make it even more misleading.<br /><br />This is NOT a 5 LB bag, it is a 2.5 LB bag, which means you're paying twice as much per ounce as you should.  This is a comparable price for the 5 LB bag.  The seller needs to change both the description and the picture, otherwise they're going to keep cheating customers.<br /><br />All of that is a shame, really, because this is a very high quality food that my cats love. I recommend this kibble highly.\",\n",
      "       b'For a product that calls itself \"Fruit Thins,\" my first question after trying one has to be \"where\\'s the fruit?\"  There is a decidable lack of fig and/or fig-taste in these cookies.  The fig that is in there consists of dry and tasteless little chopped bits that are often so hard that sometimes you think you might have bitten a stray piece of shell.  These hard bits have a tendency to get stuck in your teeth where they soften to the point of sticky.  Yuck.<br /><br />As for the cookie part, that\\'s a different story.  The cookie itself is thin, light, and crisp, and has a nice honey flavor.  However, if you\\'re a Fig Newton lover thinking to give these a try as an alternative to the original, then my advice would be to stick with the old \"fruit and cake\" and give these a miss.',\n",
      "       b'This is a decaf for people who like a \"real\" cup of coffee.  It is strong and full of coffee flavor.  Most decafs we\\'ve tried are kind of weak.  I would give it 5 stars, but sometimes I do get an odd aftertaste that I associate with decafs.  I don\\'t taste it every time, so I wonder if it\\'s because the K-cups get old?  We don\\'t go through the decafs as fast as the regular.<br /><br />For those of you that know New Orleans coffee (with chicory), this is different.  No chicory, just good coffee.',\n",
      "       b\"I have purchased many varieties of protein cocoa's; however, this was the worst one I've tried yet. It had a funny flavor to it, and despite many attempts, I could not get the clumps to dissolve. I will be throwing the rest away.\",\n",
      "       b\"We use this tea in our office and it's very popular.  Makes a nice cup of tea.  Of course it'd be cheaper to use tea bags but this is so easy and it makes the tea the perfect strength which is nice.  If you don't feel like steeping your earl grey this is a nice choice.\",\n",
      "       b\"After watching the documentary (Candyman) I really wanted to like these. I waited until they showed up on Amazon and promptly ordered a box.<br /><br />They shipped quickly, and arrived well packaged. A few of the beans spilled over into other sections, but that was easily remedied.<br /><br />I couldn't wait so I started right away. The box smells like scratch and sniff stickers, or those smelly markers, which honestly surprised me because of their commitment to natural flavorings. Very off putting.<br /><br />Here goes:<br /><br />Texture: I don't know if it's just a personal thing, but the textures are all off. A few are a little chalky, while the rest are way to soft. They stick to your teeth way too much. Somehow they are grainy also. Again, I'm used to the chewy texture of Jelly Bellies...<br /><br />Flavors:<br /><br />The fruity flavors have a weird salt flavor. Almost like energy gel or the Jelly Belly Sport beans. It's a little strange...<br /><br />Bacon: I tried. I couldn't finish it. It tastes like a cup of sugar with a fat piece of bacon in it. Good if you like your bacon drowned in sugar.<br /><br />Black Cherry: It tastes like sugar and not much else. I tried it several times to see if I had gotten a dud, but they don't taste like anything...none of them.<br /><br />Blueberry: It tastes way too salty with some granola overtones and a sour finish...weird, but not so bad.<br /><br />Coconut: If it weren't for the texture this would be awesome. Great coconut flavor.<br /><br />Cranberry: It almost tastes like sour raisins...weird. It has a cranberry juice aftertaste...I really wanted this one to be awesome.<br /><br />Ginger: Awesome. Awesome...very strong ginger flavor.<br /><br />Grape: So salty...almost a little like grape, but it really tastes way too salty with some chemically background flavors. Not good.<br /><br />Green Apple: So bad...it tastes nothing like apple at all. So bad.<br /><br />Himalayan Sea Salt: Really weird, salty, but also off puttingly sweet.<br /><br />Lemon: Tastes like lemon Pledge.<br /><br />Orange Punch: Totally Sunkist. Awesome.<br /><br />Peach: It totally tastes like Peach rings. If you eat it quickly to avoid the chemical smell, this is totally one of the best flavors. Eat it quickly though.<br /><br />Pomegranate: Tastes more like Cherry, but it isn't too bad. Doesn't taste like Pomegranate though.<br /><br />Root Beer: The best flavor. Without a doubt.<br /><br />Strawberry: One of the best. Not bad.<br /><br />Vanilla: Tastes like vanilla bean. Kind of like melted vanilla ice cream.<br /><br />If it weren't for the inconsistent textures, the chemical smell, and the bad fruit flavors these could be good. Which is really a shame since the fruit flavors are usually my favorite jelly bean flavors. Personally, for now, I'm sticking with Jelly Bellies. Dang.\",\n",
      "       b\"I tried this coffee once and I am throwing away the rest. The taste is very artificial.<br />Schuil's coffee also has cherry flavor and it is so much better.\",\n",
      "       b'Great product at a super price.  The pigs ears are better than some of the other shippers of bulk pigs ears.  We have two Labs and they love them.',\n",
      "       b'This product has made my hair super soft and shiny since I started using it. I find that using the quarter size amount is to much for my mid-back length hair. I use about a nickel size amount and it seems to do great in my hair. I moved to Germany and my hair started to feel rough, frizzy, and dull. This product, along with Mane&Tail Shampoo and TRESemme Thermal Recovery Conditioner, brought my hair back to life.....soft, shiny, and no more frizz! Highly recommended!',\n",
      "       b'The taste, packaging was off in almost every way.<br /><br />The taste, packaging was off in almost every way.<br /><br />The taste, packaging was off in almost every way.<br /><br />The taste, packaging was off in almost every way.',\n",
      "       b\"Just like the 3-star reviewer, I was prepared to be blown away after looking at the reviews, but my tastebuds are certain that this is the same or maybe just slightly better than the BumbleBee tuna in the gold cans - usually around $2.50 at Walmart.  Same size chunks, same color, same mellow taste.  The olive oil used might be a bit better but I drain it out anyway.<br /><br />I'd say if you like this, then go check out the BumbleBee in the gold can and save a few bucks a can.\",\n",
      "       b\"These are excellent seeds for COOKING, and these seeds are certainly high quality... but if you're looking to  get HIGHLY impressive reviews about your seeds and where you get them I would look elsewhere.  They are VERY CLEAN.<br /><br />For cooking they're great I suppose.  PST no.\",\n",
      "       b'These almonds are very tasty and popular at my workplace. If you\\'ve had wasabi peas, you\\'ll probably like these too. \"BOLD\" is a bit of an overstatement, as these almonds are not as intense as the peas with the nasal burn, but still do have a bit of kick. I wouldn\\'t say the soy sauce flavor is that apparent, though, but I\\'m not counting that against the product.<br /><br />Most wasabi-flavored snacks really contain horseradish because it is a cheaper substitute. Wasabi is notoriously difficult to cultivate and the chemicals that give it its characteristic pungency are volatile.<br /><br />I like these a whole lot and routinely buy several cans of them from my drugstore whenever they are on sale. My mom\\'s factory wo-workers like these too. However, I took this to a baseball game and it was almost universally hated. Go figure!',\n",
      "       b'I am a big fan of Suave and since this product is made by the same company, I jumped at the chance to try something new from them. I have to say my review may be tainted by the way the product came to me. First, when the package arrived, it was leaking. The bottle was inside a plastic bag which must have been made to seal in any leakage. I don\\'t know if it was broken or the button on top somehow got pushed, but half of the bottle of shampoo was out. Once I cut off the wrapping and threw away the spoils, the bottle seemed okay. I put it in my shower, eager to try it the next morning.<br />The shampoo itself is okay. It smells and feels like the \"color seal\" shampoo you get in a hair-dye box for after rinsing. I\\'m not found of that sort of smell everyday, but it\\'s not unpleasant. After using the shampoo for a couple of days, my hair felt limp and oily compared to using Suave shampoo and conditioner (I like to use Mango Mandarin, Citrus Smoothie, or Apple). For someone who\\'s hair is usually light, healthy, and shiny, I did not like the effect this shampoo gave to my hair. For someone who tends to have dry scalp, it might help you. I stopped using it after a week.<br />After a few uses, the bottle started leaking from the (almost) invisible seam holding the lid on. I don\\'t know if I got a messed up bottle or if this is how they all are. I would not buy this again.',\n",
      "       b\"NO RETURN!  NO REFUND!  The texture of all of the Miracle Noodle products is like eating plastic fishing worms.  I read the reviews and tried every way possible to improve the experience of eating this stuff.  5 minutes of rinsing, par boiling etc.  When you buy this item you are stuck with it.  Amazon.com will not stand behind the quality of your experience.  Don't take a chance of losing $80 like I did.\",\n",
      "       b'MIO Sweet Tea is indeed \\'sweet\\', so if you don\\'t like sweet things, don\\'t bother with this flavor enhancer for your water. The tea flavor does come through too, but it\\'s subtle.  No strong aftertaste with this flavor of MIO and all things considered, it really is one of the best I\\'ve tried from their many flavors. I kept thinking to myself as I sipped away on my Sweet Tea flavored water - \"If I was on a diet and needed something sweet instead of a soda, this would be it!\"<br /><br />So if you\\'re looking for a sweet with no aftertaste drink, that is as close to a regular soda in that \\'sweetness\\', snag some MIO Sweet Tea flavored drink enhancer.  If you are more inclined to enjoy diet sodas, you\\'ll find this too sweet.  Backing off the amount in your drink doesn\\'t really help much as for me at least, the tea flavor was always much fainter than the sweetness.',\n",
      "       b\"I love sweet tea, but this one is too sweet. From the reviews, I was excited but I don't think I am going to finish the box. Very convenient way to make sweet tea, but I wish it tasted better.\",\n",
      "       b'I like Dogswell products and have purchased the \"Vitality\" Chicken Chews before (which are actually chewy). But these sweet potato chews are hard as a rock! I seriously couldn\\'t even chew them, it was like biting a lolipop or jawbreaker - way too hard.  My dog and my roomie\\'s dog didn\\'t care for them one bit.  I purchased them because they were on sale (deeply discounted) and now I know why....<br /><br />Buy other Dogswell Chews, just not these sweet potato ones...',\n",
      "       b'The bones are ok. My pup chewed through one of these in about 10 mins. She seemed to like it, but I was hoping it was more of a chew-style toy rather than a quick snack.',\n",
      "       b'This DVD did not fit in my DVD player. I was very excited about this movie, what a disappointment. Perhaps my DVD player is not compatible with 100% juice?',\n",
      "       b\"I love Lindt and was really hoping for great things with this 90% bar; alas, it is just too bitter and chalky to eat straight.<br /><br />I consider myself a hardcore chocoholic and can handle intensity on the choco scale. But this is more or less like baking chocolate. There is almost no sugar in it, and while that may be good for flavor, it's almost inedible on its own.<br /><br />I'm confused by those who rated it so highly but I guess taste is totally subjective. I'm usually the one of my friends who likes the darkest, least sweet chocolate, but this is just not working for me at all.\"],\n",
      "      dtype=object)>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([3, 2, 3, 4, 0, 3, 1, 4, 0, 2, 0, 1, 2, 3, 0, 3, 1, 0, 4, 4, 1, 3,\n",
      "       0, 3, 1, 0, 3, 2, 0, 2, 1, 1], dtype=int32)>)\n",
      "(<tf.Tensor: shape=(32,), dtype=string, numpy=\n",
      "array([b\"Chef Boyardee was a childhood favorite but I didn't remember ever getting plain cheese ravioli so I snagged some. I am not sure what kind of cheese it was but it over powered everything and not with a cheesy taste. I had 12 of them so to finish them off I gave a few of them to my cat and mixed a few with beef ravioli which worked out great.\",\n",
      "       b'This is a great tea. I started visiting chinese websites to gain insight on healthy teas and habits because of couse the Chinese are very wise when it comes to their healing and habits. I can tell you that this tea has made me feel sooooo much better! I mean I used to feel sluggish and constipated (sorry) not any more. It turns out this specific tea was reviewed on Dr. Oz (youtube it) as the best tea to drink first thing in the morning to loose weight. So far this is true. Add a very very small amount of honey and you are all set. Doesnt taste like anything and doesnt make your stomach run. Do it!',\n",
      "       b\"I don't know what it tastes like. I just know that that this item came up on a gluten free search but it is not gluten free. It contains semolina and semolina is wheat.\",\n",
      "       b\"Used one pkg. of this product to make muffins, appearance and texture were good,<br />but they had a chemical taste and unpleasant odor and I won't use the other two<br />packages.<br /><br />S. Bowman\",\n",
      "       b\"I bought these during Amazon's 4/3 promotion.  I have two golden retrievers who are spoiled badly and I am constantly looking for healthy treats for them.  These are perfect because I can open one package and have one bone for each dog.  They love these and sit waiting for them.  They are not soft but not like rawhide so when they chew on them, it helps clean their teeth.  There are enough vitamins and flavor to keep them interested until the whole bone is gone.  I would definitely buy again.\",\n",
      "       b\"I have ordered this item many time in the past and have loved it. However, this time it is FLAVORED! And we hate flavored coffee. Maybe it's a mistake.\",\n",
      "       b'Great price on Pill Pockets.  Our one dog does not like cheese or peanut butter (imagine that!).  These fit the bill perfectly.',\n",
      "       b'Came out very flat and eggy which I cannot stand.  So I played and discovered if you add to the recipe one of the dixie bakesquick inner packets and a tsp vanilla to the mix (no additional fluid) you get real pancakes that are nice and fluffy and taste whole grain.  The batter will still be runny.  It ups it to being 3 carbs a pancake instead of 1 but that is still super low.<br /><br />  Also, you do not have to add heavy cream, the instructions give alternatives with egg beaters and sour cream to lower the calories.<br /><br />  I would suggest these but only if you get bakesquick too.',\n",
      "       b\"I taste all the foods I feed my daughter, and I usually like Sprout's flavors, but this has too many flavors.  My daughter will eat it, but not as a first choice, plus the beans give her gas.\",\n",
      "       b\"I bought this in a Long Island gas station was amazed by the taste for only 35 calories! I then had to buy some online to see maybe one bottle day would effect my mood. I had one everyday for about two weeks and although tasty and low calorie, I did not see any effect on my mood. If it were cheaper, I would buy it just to drink daily whether or not it made me 'blissful' but at about 2.50 a bottle, it's just not worth it.\",\n",
      "       b\"I must be spoiled because this coffee was very good but just didn't reach greatness.  I like the Britt Costa Rican better.  But, this coffee is more economical and can be used to please a crowd.  Keep the Britt for yourself.\",\n",
      "       b'I think these chips are awesome if not the best along with Poor Brothers Salt and Vinager chips. But if you buy these Spicy Thai chips in a smaller bag it might have too much of the flavor (at the bottom of the bag) in it then the larger bag at least that was my experience last time I bought these off amazon but that was like in 2010. So I would suggest trying Spicy Thai in a bag bigger then 5 ounces.',\n",
      "       b\"I ordered this product because it was slightly less expensive than the brand that I'd ordered previously. Neither had received rave reviews and I was pleased with the other brand but thought I'd give this a try and save a few bucks, and the packaging looked a bit higher end. WRONG. The other brand (Roland Black Whole Grain Lumpfish Caviar, 2-Ounce (Pack of 4) )is far superior to the Romanoff brand. As other reviews stated, there are many undisclosed additives, and it had a nasty green slimy texture.  Even mixed with egg salad, it had a terrible aftertaste. Ate it about an hour ago and still feel queasy. Spring for the extra five bucks and get the Roland brand if you want an affordable indulgence.<br />Amazon was GREAT about this. They credited me the full value toward my purchase of the Roland, as the Romanoff product isn't returnable since it is a grocery item. Still loving Amazon!\",\n",
      "       b'I personally did not care for the coffee, too mild for me and a little \"nutty\" flavor in it.  I will stick with Tully\\'s Kona and House blends, also Emeril\\'s Big Easy bold.',\n",
      "       b\"I thought the bonsai was a cute little tree at first, but I noticed little bugs on my desk where I kept the tree.  I didn't think about why they were they at first, but after 2 weeks, I noticed the tree was crawling from little mites that were coming up out of the soil.  I'm sure the seller didn't intend on this happening, but I'll never order another bonsai.<br /><br />Addition - Seller was great.  They recieved my email about the bus & offered me a full refund.  They explained it was not intentional & that flooding in their area may have caused it.\",\n",
      "       b\"I LOVE Kind bars, but these are terrible.  Upon taking one bite they tasted stale and not like any other Kind bar product I purchase on a regular basis. I litterally had to spit it out after taking a bite...and that's extreme..sorry!!  Steer clear of these new bars, I really think something was wrong with them, again I couldn't return due to Amazon's policy.  Very disappointing.\",\n",
      "       b'I had high hopes for this cereal, as I am a big peanut fan.  However, while the cereal itself is \"not bad\" it\\'s lacking in many areas.<br /><br />First and foremost it\\'s not made with whole grains like Honey Nut Cheerios is.  Another reviewer put it nicely when they said this is equivalent to eating candy for breakfast.  The amount of sugar and refined carbohydrates is way too much for any type of health benefit whatsoever.  The peanuts are so small and in such small pieces (more like granules) that I don\\'t consider them anywhere near enough to consider any health benefits from the nuts.<br /><br />The taste itself is good, and it\\'s a bit softer of a crunch than most cereals, but outside of that it\\'s just too many carbohydrates to be on the breakfast table.  Kellog\\'s could really improve this cereal by getting rid of some of the added sweetners and switch to a whole grain recipe.  Until then, if you like sweet cereals with little health benefits then this is for you -- but otherwise, stick with Honey Nut Cheerios.',\n",
      "       b'This is the 2nd time I have ordered and these cookies arrived packed in the box, not in a plastic bag as the previous order.  The cookies were stale.  The first order was definitely fresh - this order was extremely disappointing.  I will probably go back and pay a little extra to pick up the 12 unit box at the local grocery - I am very disappointed in the quality and freshness of this product',\n",
      "       b\"roduct arrived timely. Six boxes. I sampled this tea in a resturant and it was delicious. Can't say the same for my purchase. Good tea, but not as flavorful as Bigelow.\",\n",
      "       b'I needed some extra equipment and this was a good buy. They did ship it promptly. The capper is not the one pictured but the basic black beauty...',\n",
      "       b\"The Jeremiah's 5lb bag of Ethiopian coffee is often sold-out, so I've been looking for a good roast with similar value. I'm OK with a more medium roast, but this coffee seems more mild then I would have expected. Still a good deal, but I wish it had more flavor. In general, I've had good luck with Jeremiah's brand, although sometimes the bags are not as well-sealed as they should be.\",\n",
      "       b'These are expensive and every one was smashed. I complained to no avail not even an answer.',\n",
      "       b'What happened.  I have been getting these for a year and the cost has been around $17.  Now they are $27.  I did not recieve a notice on my subscription, so amazed that this happened.  What do other think?',\n",
      "       b\"I ordered this product on Amazon to get some of the flavors we can't get in the US, namely, bacon, worcestershire, and prawn cocktail.  The photo of the product was so small and the description was so vague that I didn't realize until it came that what I was getting were actually 3 flavors of crisps that I can get down the street from my house:  cheddar cheese and onion, salt and vinegar, and regular flavor.  I was VERY disappointed.  Instead of trying again to order online, I will ask friends in the UK to shop and mail them for me.\",\n",
      "       b\"The Merrick Puppy Dry Dog Food was $22.25 for a 17.5 lb bag.  Now it's $28.52 for the 17.5 lb bag.\",\n",
      "       b\"This burger is OK. You can do better at a local store. Omaha's steaks are good.<br />Buy the steaks.\",\n",
      "       b\"These are really good, we ate the entire box of 5 bars within about 7 days.<br /><br />A big selling point for these is that they have 7 grams of protein, and since we are active people we need the protein.<br /><br />These are not the sugary fare that many people desire.  if you are craving a candy bar then well, you can't really expect this trick your taste buds.<br /><br />What it has is a really well formulated nut flavor.  The size, claiming to be 30% bigger, is enough to satisfy you.  My wife has sometimes felt that she could have thrown away the last bite, but was usually happy she did not.<br /><br />The only reason I didn't give this product 5 stars is that it uses corn syrup, and personally I am not fond of all this corn syrup.  I am very happy to see that many of the items in the grocery store are switching back to cane sugar, and I hope that Planters sees the light.  I won't go into the anti-corn syrup rhetoric here as I don't feel its in the scope of this review.  Just be aware that it isn't very good for you.\",\n",
      "       b'I have consumed many kinds of honey.  This honey is the thinnest one.  It is so thin that I am suspicious whether it is 100% honey (water added?).',\n",
      "       b'Sounded like an interesting product, but I don\\'t like the consistency. It\\'s hard to describe, but I\\'ll say that it was a little \"greasier\" than I expected. It didn\\'t work well with our salt grinder because granules got stuck and plugged it up. I don\\'t really have a comment on the taste. The delivery and packaging, etc., was fine, but this is just not my favorite.',\n",
      "       b'While I agree this is shipped in a nice wooden box that can be used for other things and the fish has an excellent flavor, I was surprised to find it was not what I expected.  I expected smoked lox salmon like you find at a good deli or grocery store, not fully cooked salmon as this actually is.  For those expecting the latter, this is a great product, however this is not for me as it was smoked (or cooked) too long.',\n",
      "       b\"I lust for Artisana coconut butter. I use it like peanut butter on toast, in oatmeal in the morning, even out of the jar although it's so rich it can be sickening like that (learned the hard way :). Anyway I saw this and it looked like the Artisana at almost half the price. So it's not raw, which is likely why that one is more expensive, but it tastes just as good and makes my wallet happy.<br />To the reviewers who were disappointed - it's definitely NOT like coconut oil, you MUST stir it up, it's a very versatile product to use as a replacement. I foresee ordering more in the future.\",\n",
      "       b'No DOP or Consorzio San Marzano stamp but this product is outstanding compaired to the cost.<br />Arrived well packaged without damage,'],\n",
      "      dtype=object)>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 3, 0, 1, 4, 0, 4, 3, 2, 2, 3, 3, 0, 1, 1, 0, 1, 0, 2, 3, 2, 0,\n",
      "       1, 0, 1, 1, 3, 0, 2, 1, 3, 4], dtype=int32)>)\n",
      "(<tf.Tensor: shape=(32,), dtype=string, numpy=\n",
      "array([b'Use with caution. When my baby was 5 weeks old I noticed that my milk supply was decreasing. I was taking 2 pills 3 times a day for about a week when I started felling really sick. I head strong headaches, I was weak and I had problem with breathing. My baby had a cough and was spitting up milk. She could not swallow, the mucus in her mouth was very thick. I learned from my doctor that fenugreek has very dangerous side effects: it can cause asthma;  reduces blood glucose levels which means it is not right for diabetics; promotes menstrual flow and can make yor menstrual cycles abnormal. I spent money on pills, teas, drops and my milk supply did not increase at all. I can breastfeed my baby only once a day now. I am happy with what I can give her although I see clearly that she hates formula. I give only one star because the manufacturer does not warn about side effects the product can have on mother and her child. I bet they know the pills are used mostly for the purpose of increasing breastmilk supply, yet they do not care about us.',\n",
      "       b\"The only treat my fussy Siamese will eat.  I don't mind.  These are actually good for her and don't upset her otherwise sensitive stomach.\",\n",
      "       b\"I just received this product, and it tastes funny and sour.  I don't know if I just received a bad batch or if this is how it supposed to taste.  But yuck! I threw it in the garbage.  It doesn't taste anything like regular chocolate syrup.\",\n",
      "       b'I bought this product thinking it was a high quality demi glace. It is an ordinary brown gravy which would be wonderful if served in a high school cafeteria or budget restaurant. There is a reason it is well priced. You get what you pay for. Be sure you know what you are ordering before you buy this.',\n",
      "       b\"I have never cooked with porcini before and bought 16oz of these. They smell so amazing and the flavor is just wonderful! I made a soup of barley, italian sausage, and mushrooms.<br /><br />Though I must warn you... I only soaked about 1/3 of a cup of dried mushrooms and got a dime sized pile of re-hydrated worms. These things are infested! After an internet search I found that this is apparently a normal occurrence. I can't image the amount of worms I got was supposed to be normal though.<br /><br />The mushrooms were limp and looked very unappetizing on my spoon (could have been the cooking time, could have been the fact I could see the little worm paths in the mushroom), but that was some of the best tasting broth I have ever had. I think what I will do is just hydrate them and use only the strained liquid.<br /><br />I never thought I would give an ounce of respect to a food filled with worms.\",\n",
      "       b\"A few drops of MiO caused the water in my glass to turn brownish red. I tasted it. A somewhat pleasant bitter-sweet, vaguely hinting at Cr&egrave;me Br\\xc3\\xbbl&eacute;e or maybe just burned sugar. Strange, not unlike the plain Peach flavor I sampled the other day. I finished the glass and the good news is that 24 hours later there were no side effects other than some mild aftertaste that slowly faded away and changed into more bitter and less sweet. The even better news is that the MiO does not seem to be addictive but time will tell.<br /><br />My review sample had a sticky label over the contents disclosure but patience goes a long way. This is what I learned after I removed the sticky: this product contains mostly... nothing worth talking about. 0 calories, 0% fat, 0% sodium, 0% carbs, 0% protein. It has no or only trace amounts of cholesterol, fiber, saturated fat, transfats, Vitamin C, Calcium or Iron.<br /><br />Then... what is this tea made of? Not of peaches or mangoes for sure. According to the ingredients list, the main ingredient besides 'water' is Propylene Glycol. It's worth checking it out on the Wiki because it's a very useful chemical. They have a long list of good uses there including as a: solvent used in mixing photographic chemicals, working fluid in hydraulic presses, the main ingredient in deodorant sticks, the killing and preserving agent in pitfall traps and to capture ground beetles, cooling agent for beer and wine glycol jacketed fermentation tanks and so many other useful activities such as to regulate humidity in a cigar humidor.<br /><br />All of this is great because, like I said, one day later I'm still okay and smell like a rose or... Cr&egrave;me Br\\xc3\\xbbl&eacute;e? - the deodorant effect - but... where's the tea? I am going to grant this product 2 stars because, after I consumed it in moderation (one glass) it did not make me sick. I'm not planning to drink any more but I'm thinking about using it as bait for Japanese Beetles this coming summer.\",\n",
      "       b\"Firstly, I do drink a fair amount of coffee during the winter months.<br /><br />Nevertheless, I tend not to drink flavored coffee.  This is ground, flavored coffee.  Starbucks has not previously offered flavored coffees themselves because they know it will contaminate unflavored coffee in a grinder.  They are getting around this by only selling the coffee pre-ground, therefore, no customer will ever request it to be ground.<br /><br />When first opened, the quality is decent despite being pre-ground.  However, I do find, the quality of the product slips away fairly quickly being a ground coffee.<br /><br />Furthermore, again, I am not a particular fan of flavored coffees.  If I need a sweetener or flavor, I'd prefer to add it myself.  Nevertheless, this  vanilla flavored product is not terribly unpleasant.  I was able to enjoy it on a quiet morning or two when I wasn't demanding the very best.<br /><br />If flavored coffees is your thing, you will likely have no problems at all!\",\n",
      "       b\"For some reason known only to Amazon, these bread crumbs pop up third in the list when you search for gluten free bread crumbs. I trusted the search (and all the others it found seem to be gluten free) and didn't read far enough down in the description (so yes, this is completely my fault) and, since this was a subscribe and save deal, ordered these. I just got them today and discovered that I can't use - or return - any of the six containers I ordered because they are not, in fact, gluten free. It would be nice if there were some way that items containing gluten did NOT pop up in a search for items that do not contain it. I'm giving them four stars anyway because I'm sure they probably taste lovely. I will never know.\",\n",
      "       b'This is one of my favorite cups of coffee. I will definitely be purchasing more of this.  The flavor is a little weak on the biggest cup setting on my Keurig but the middle setting is perfect and you can really taste the Butter Toffee.  I love it!!  Try it on the smallest setting for a really sweet treat.',\n",
      "       b'I purchased this as a moisturizer for my hair.  Very faint rose smell, almost non-exsistent.  On the bottle the ingredients listed are 50% distilled water and 50% rose petals; that must be a mistake because all I smell is water.',\n",
      "       b'I thought for sure I was going to love this tea. I love licorice and I like my teas sweet. I was so disappointed in the flavor of this product! It has very little licorice taste and an almost sickening after taste and smell. I added sugar to it as I did not find it very sweet. I ordered the 6 box pack of this so I guess I have 5 boxes of it to give away',\n",
      "       b'Good price but the coffee lacks aroma and flavor. To be a Colombian you expect more Arabic qualities. Also require extra ammount to get a decent flavor.',\n",
      "       b\"Dr. Flynn's Organic Granola is probably the best granola I've ever tried. It's a terrific way to start the morning, especially with a bit of milk. The flavor is wonderful, with lots of cinnamon and nuts. Even the raisins fit in well, and I'm not the biggest fan of raisins.<br /><br />I'd highly recommend this granola if you're looking to try something new for breakfast!\",\n",
      "       b'The Maca powder came in the same box as the truck ball mount and tore open he Maca bag.  The ball mount, which is metal,  should<br />have been wrapped in bubble wrap.  The Maca powder was all inside the box.  Poor poor poor pacaka<a href=\"http://www.amazon.com/gp/product/B000FFLHU2\">Navitas Naturals Organic Raw Maca Powder, Incan Superfood, 16-Ounce Pouch</a>ging.',\n",
      "       b'As others have noted, these treats are made in China as clearly stated on the bag. I didn\\'t like that, but the news gets worse.<br /><br />On the back of the bag is a statement: \"Not for human consumption. Wash hands with soap and water after handling.\"<br /><br />If I have to wash my hands after handling these things, I\\'m sure as hell not going to feed them to my Yorkies!<br /><br />As expected, Amazon graciously accepted a return.',\n",
      "       b\"I was hoping that there was somehow a flavored water drink with good flavor without sugar or chemicals.  I am still hoping.  Hint does have exactly hint which is what I should of expected.  It's just too expensive of a drink to buy when it really doesn't taste much different than regular water.\",\n",
      "       b\"It just doesn't taste like butter to me. Highly concentrated or no, it tasted closer to garlic or something. Maybe it's just me, but this stuff was awful.\",\n",
      "       b'After reading the reviews, just want to mention that the price is for 2 packages of t-discs, so it is a decent deal.',\n",
      "       b\"The tea and the passion fruit flavor were good, a little on the sweet side for me. Plus it left an aftertaste that was a bit too intense. It didn't have a refreshing feel to it like I usually get from tea or fruit drinks. Also, there was a lot of pulp in the bottle. It was thick, plump, big and chunky. I tried shaking the bottle vigorously but that didn't help break it up. The pulp stayed consistently firm. It ruined the drink for me. You might like this if you enjoy lots of pulp and in fairly large pieces but it wasn't right for me.\",\n",
      "       b'I bought these \"kcups\" to save money as the cost on my usual Kcups rose to 51 cents a cup on subscribe and save and I could not find them cheaper anywhere else online or locally. These ecocups produce a nice cup of medium strength coffee (not as strong as a regular Kcup). I use the Fog Chase and French Roast on the 12 ounce setting but the Rainforest is too weak to use  so I have to use the 8 ounce setting. The Big plus with these ecocups is that they are really good for use with your own coffee! I use DisposaCup Lids to refill these ecocups over and over again! That\\'s a great vaule at 38 cents a \"Kcup\"!! <a href=\"http://www.amazon.com/gp/product/B004NM9YW6\">DisposaCup Lids - 100 Disposable Replacement Lids for Use with Any Keurig K-cup - BOX of 100 LIDS</a>',\n",
      "       b\"I remember these having a lot more meat on them. Now they are just basted with juice. My dog won't eat them.\",\n",
      "       b'Dog broke the hard plastic the first day by slamming it around by the rope so we have to tape it up everytime we refill. Dog does enjoy, carries it around wanting to play fetch but settles on tug a war. It does keep him occupied trying to get the food out. Container needs to be made of different material to prevent breakage but still worth the money for the enjoyment it has given him.',\n",
      "       b'It has gotten very hard to find Wrigleys Spearmint gum.  It nice to find it through Amazon.com.',\n",
      "       b'These crackers taste great and allow the flavor of what ever you put on them to be the star instead of the cracker over powering the toppings flavor.<br /><br />They are not zero points on the Weight Watchers Points Plus Plan - if you have 18 crackers its 2 points, if you have 9 crackers its 1 point, if you have 5 crackers its 0 points.<br /><br />5 crackers are plenty with some egg or tuna salad for lunch or as a snack.<br /><br />I use them with pineapple or mango salsa which are either 0 points or 1-2 points depending on how much salsa you eat.',\n",
      "       b\"The nut are fresh and a good value for the money, the reason I only gave them 3 stars is because their not very salty. Part of the enjoyment to me, when eating pistachio's is sucking the salt off the shell before I crack it open and eat the nut. If you don't care about this, it is a good value.\",\n",
      "       b\"I was pretty excited when I bought the B70 for my wife, she likes coffee and I'm a hot chocolate drinker.  I ended up buying the Cafe Escapes, got it home, put it in the brewer and the last half second that comes out of it is clear water, thought right away uh-oh real bad sign.  I added some milk to the finished product, topped it with some whipped cream, took a nice sip and thought wow this cup of hot water tastes just like a cup of hot water with some chocolate in it.  The next step was to Escape (BAM!! RIM-SHOT!!) from this horrible cup of hot chocolate, walk over to the sink and poor it down the drain.  Don't waste your money.<br /><br />I guess I'll stick to boiling my milk on the stove for 10 minutes, pouring in 4 nice scoops of Nestle Quik and enjoying a real hot chocolate.\",\n",
      "       b\"I have bought many brands on peanuts on Amazon. I was a tad disappointed in this brand. The Peanut Shop Of Williamsburg. The over all flavor was ok. Not a strong flavor but not weak. I found the salting to be a little on the light side. That's fine with me, I use most of my nuts in kung-pow type dishes, and the lower salt is fine. The crispness was very poor for a hand cooked kettle peanut. It really should have more crunch/snap.  Over all this is a step up from Planters cocktail peanuts. But you can do much better with other brands.\",\n",
      "       b\"The taste of this product in my opinion is NASTY to say the least.<br /><br />Nestle's should bring back the recently discontinued (Milk Chocolate) flavor 50000 11164<br /><br />Nestle's you BLEW IT by dropping the Milk Chocolate flavor.<br /><br />Not everyone likes coffee or hot chocolate that is so thick or taste like MUD!!!\",\n",
      "       b'Of the 6 bags, two that I have opened thus far have defective pods that have spilled coffee grounds throughout the bag.  Hence, I cannot use any of the pods as they are covered with coffee grounds.  I tried to return them, however the Amazon website states that they are not eligible for return.',\n",
      "       b'I am crazy about chocolate and raspberry, so this really appealed to me.  (I even put fat free chocolate milk in my regular decaf in the AM.)  This coffee has a milder chocolate flavor than that does.  I also like a very strong coffee, and this is milder than that which is why I gave it 4 stars.  If you want a somewhat mild coffee and somewhat mild chocolate raspberry flavor than this is for you.',\n",
      "       b\"These have a nice spicy flavor.  Too bad they don't sell these in regular stores so you don't have to order in bulk but they are worth it.\",\n",
      "       b'I have always bought Kona 100% coffee.  This time I bought Jamaica Blue Mountain coffee.  I was not impressed.  The coffee beans did not smell fresh and the taste was not the smoothness I expected.  I really expected better and for the price I expected what it advertised. I would not recommend this coffee.'],\n",
      "      dtype=object)>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([0, 3, 0, 0, 2, 1, 2, 3, 4, 0, 1, 2, 4, 0, 0, 2, 0, 3, 1, 3, 0, 3,\n",
      "       4, 4, 2, 0, 2, 0, 0, 3, 3, 1], dtype=int32)>)\n"
     ]
    }
   ],
   "source": [
    "for row in train_ds.take(3):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0 corresponds to 1\n",
      "Label 1 corresponds to 2\n"
     ]
    }
   ],
   "source": [
    "# Looking at what labels correspond to what ratings\n",
    "print(\"Label 0 corresponds to\", raw_train_ds.class_names[0])\n",
    "print(\"Label 1 corresponds to\", raw_train_ds.class_names[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
     ]
    }
   ],
   "source": [
    "# Now we will load up a model with TensorFlow Hub\n",
    "# We will be using a small BERT to start with\n",
    "# to read about all the BERT model available click this link\n",
    "# https://colab.research.google.com/drive/1UytfDnUpCQTHK8BA8n__B4YCWm4gzIeW#scrollTo=dX8FtlpGJRE6\n",
    "\n",
    "\n",
    "\n",
    "#@title Choose a BERT model to fine-tune\n",
    "\n",
    "bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8'  #@param [\"bert_en_uncased_L-12_H-768_A-12\", \"bert_en_cased_L-12_H-768_A-12\", \"bert_multi_cased_L-12_H-768_A-12\", \"small_bert/bert_en_uncased_L-2_H-128_A-2\", \"small_bert/bert_en_uncased_L-2_H-256_A-4\", \"small_bert/bert_en_uncased_L-2_H-512_A-8\", \"small_bert/bert_en_uncased_L-2_H-768_A-12\", \"small_bert/bert_en_uncased_L-4_H-128_A-2\", \"small_bert/bert_en_uncased_L-4_H-256_A-4\", \"small_bert/bert_en_uncased_L-4_H-512_A-8\", \"small_bert/bert_en_uncased_L-4_H-768_A-12\", \"small_bert/bert_en_uncased_L-6_H-128_A-2\", \"small_bert/bert_en_uncased_L-6_H-256_A-4\", \"small_bert/bert_en_uncased_L-6_H-512_A-8\", \"small_bert/bert_en_uncased_L-6_H-768_A-12\", \"small_bert/bert_en_uncased_L-8_H-128_A-2\", \"small_bert/bert_en_uncased_L-8_H-256_A-4\", \"small_bert/bert_en_uncased_L-8_H-512_A-8\", \"small_bert/bert_en_uncased_L-8_H-768_A-12\", \"small_bert/bert_en_uncased_L-10_H-128_A-2\", \"small_bert/bert_en_uncased_L-10_H-256_A-4\", \"small_bert/bert_en_uncased_L-10_H-512_A-8\", \"small_bert/bert_en_uncased_L-10_H-768_A-12\", \"small_bert/bert_en_uncased_L-12_H-128_A-2\", \"small_bert/bert_en_uncased_L-12_H-256_A-4\", \"small_bert/bert_en_uncased_L-12_H-512_A-8\", \"small_bert/bert_en_uncased_L-12_H-768_A-12\", \"albert_en_base\", \"electra_small\", \"electra_base\", \"experts_pubmed\", \"experts_wiki_books\", \"talking-heads_base\"]\n",
    "\n",
    "map_name_to_handle = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/google/electra_small/2',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/google/electra_base/2',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
    "}\n",
    "\n",
    "map_model_to_preprocess = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "}\n",
    "\n",
    "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
    "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
    "\n",
    "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
    "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text inputs need to be transformed to numeric token ids and arranged in several Tensors before being input to BERT. TensorFlow Hub provides a matching preprocessing model for each of the BERT models.\n",
    "\n",
    "The preprocessing model must be the one referenced by the documentation of the BERT model.\n",
    "\n",
    "Note: We will load the preprocessing model into a hub.KerasLayer to compose your fine-tuned model. This is the preferred API to load a TF2-style SavedModel from TF Hub into a Keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the preprocessing model on some text and see the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys       : ['input_type_ids', 'input_word_ids', 'input_mask']\n",
      "Shape      : (1, 128)\n",
      "Word Ids   : [ 101 2023 2003 2107 2019 6429 3185  999  102    0    0    0]\n",
      "Input Mask : [1 1 1 1 1 1 1 1 1 0 0 0]\n",
      "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "text_test = ['this is such an amazing movie!']\n",
    "text_preprocessed = bert_preprocess_model(text_test)\n",
    "\n",
    "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
    "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
    "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
    "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
    "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, now you have the 3 outputs from the preprocessing that a BERT model would use (input_words_id, input_mask and input_type_ids).\n",
    "\n",
    "Some other important points:\n",
    "\n",
    "The input is truncated to 128 tokens. The number of tokens can be customized, and you can see more details on the Solve GLUE tasks using BERT on a TPU colab.\n",
    "The input_type_ids only have one value (0) because this is a single sentence input. For a multiple sentence input, it would have one number for each input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the BERT model\n",
    "\n",
    "Before putting BERT into our model, let's take a look at its outputs. We will load it from TF Hub and see the returned values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded BERT: https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Pooled Outputs Shape:(1, 512)\n",
      "Pooled Outputs Values:[ 0.762629    0.9928099  -0.18611836  0.3667385   0.15233703  0.6550446\n",
      "  0.9681154  -0.9486271   0.00216162 -0.9877732   0.0684273  -0.9763059 ]\n",
      "Sequence Outputs Shape:(1, 128, 512)\n",
      "Sequence Outputs Values:[[-0.28946263  0.3432124   0.33231494 ...  0.2130081   0.7102064\n",
      "  -0.05771117]\n",
      " [-0.28742084  0.3198105  -0.23018569 ...  0.5845506  -0.2132983\n",
      "   0.72692025]\n",
      " [-0.66157037  0.6887678  -0.87432986 ...  0.10877259 -0.26173207\n",
      "   0.47855437]\n",
      " ...\n",
      " [-0.22561176 -0.2892558  -0.07064467 ...  0.47565997  0.8327707\n",
      "   0.40025383]\n",
      " [-0.29824215 -0.27473122 -0.05450581 ...  0.48849717  1.0955354\n",
      "   0.18163371]\n",
      " [-0.44378212  0.00930753  0.07223634 ...  0.17290142  1.1833245\n",
      "   0.07898019]]\n"
     ]
    }
   ],
   "source": [
    "bert_results = bert_model(text_preprocessed)\n",
    "\n",
    "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
    "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
    "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
    "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
    "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BERT models return a map with 3 important keys: pooled_output, sequence_output, encoder_outputs:\n",
    "\n",
    "pooled_output represents each input sequence as a whole. The shape is [batch_size, H]. You can think of this as an embedding for the entire movie review.\n",
    "sequence_output represents each input token in the context. The shape is [batch_size, seq_length, H]. You can think of this as a contextual embedding for every token in the movie review.\n",
    "encoder_outputs are the intermediate activations of the L Transformer blocks. outputs[\"encoder_outputs\"][i] is a Tensor of shape [batch_size, seq_length, 1024] with the outputs of the i-th Transformer block, for 0 <= i < L. The last value of the list is equal to sequence_output.\n",
    "For the fine-tuning you are going to use the pooled_output array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your model\n",
    "You will create a very simple fine-tuned model, with the preprocessing model, the selected BERT model, one Dense and a Dropout layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_model():\n",
    "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "  encoder_inputs = preprocessing_layer(text_input)\n",
    "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "  outputs = encoder(encoder_inputs)\n",
    "  net = outputs['pooled_output']\n",
    "  net = tf.keras.layers.Dropout(0.1)(net)\n",
    "  net =  tf.keras.layers.Dense(15, activation = 'relu')(net)\n",
    "  net = tf.keras.layers.Dense(5, activation='softmax', name='classifier')(net)\n",
    "  return tf.keras.Model(text_input, net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that the model runs with the output of the preprocessing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.52529407 0.5118602  0.6105833  0.5256418  0.5741651 ]], shape=(1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "classifier_model = build_classifier_model()\n",
    "bert_raw_result = classifier_model(tf.constant(text_test))\n",
    "print(tf.sigmoid(bert_raw_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is meaningless, of course, because the model has not been trained yet.\n",
    "\n",
    "Let's take a look at the model's structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(classifier_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "You now have all the pieces to train a model, including the preprocessing module, BERT encoder, data, and classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "metrics = tf.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "For fine-tuning, let's use the same optimizer that BERT was originally trained with: the \"Adaptive Moments\" (Adam). This optimizer minimizes the prediction loss and does regularization by weight decay (not using moments), which is also known as AdamW.\n",
    "\n",
    "For the learning rate (init_lr), you will use the same schedule as BERT pre-training: linear decay of a notional initial learning rate, prefixed with a linear warm-up phase over the first 10% of training steps (num_warmup_steps). In line with the BERT paper, the initial learning rate is smaller for fine-tuning (best of 5e-5, 3e-5, 2e-5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "init_lr = 3e-5\n",
    "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                          num_train_steps=num_train_steps,\n",
    "                                          num_warmup_steps=num_warmup_steps,\n",
    "                                          optimizer_type='adamw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the BERT model and training\n",
    "Using the classifier_model you created earlier, you can compile the model with the loss, metric and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model.compile(optimizer=optimizer,\n",
    "                         loss=loss,\n",
    "                         metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: training time will vary depending on the complexity of the BERT model you have selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3/47 [>.............................] - ETA: 10:05 - loss: 1.8728 - sparse_categorical_accuracy: 0.1771"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-287-71a9fbf2d907>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Training model with {tfhub_handle_encoder}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history = classifier_model.fit(x=train_ds,\n\u001b[0m\u001b[1;32m      3\u001b[0m                                \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                epochs=epochs)\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1740\u001b[0m                         ):\n\u001b[1;32m   1741\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1742\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1743\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    855\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m       (concrete_function,\n\u001b[1;32m    147\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    149\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1347\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1348\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_call_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1457\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1458\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(f'Training model with {tfhub_handle_encoder}')\n",
    "history = classifier_model.fit(x=train_ds,\n",
    "                               validation_data=val_ds,\n",
    "                               epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  41/4594 [..............................] - ETA: 3:50:43 - loss: 0.0000e+00 - categorical_accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-9610144f1591>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Loss: {loss}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Accuracy: {accuracy}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2198\u001b[0m                         ):\n\u001b[1;32m   2199\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2200\u001b[0;31m                             logs = test_function_runner.run_step(\n\u001b[0m\u001b[1;32m   2201\u001b[0m                                 \u001b[0mdataset_or_iterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2202\u001b[0m                                 \u001b[0mdata_handler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001b[0m\n\u001b[1;32m   3998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3999\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_or_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_shards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4000\u001b[0;31m         \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_or_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4001\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4002\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    862\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m       (concrete_function,\n\u001b[1;32m    147\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    149\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1347\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1348\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_call_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1457\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1458\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss, accuracy = classifier_model.evaluate(test_ds)\n",
    "\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'amazon_reviews'\n",
    "saved_model_path = './{}_bert'.format(dataset_name.replace('/', '_'))\n",
    "\n",
    "classifier_model.save(saved_model_path, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded_model = tf.saved_model.load(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results from the saved model:\n",
      "input: This is such an amazing product!!! : score: 1.000000\n",
      "input: The product was great!         : score: 1.000000\n",
      "input: The product was meh.           : score: 1.000000\n",
      "input: The product was okish.         : score: 1.000000\n",
      "input: The product was terrible...    : score: 1.000000\n",
      "\n",
      "Results from the model in memory:\n",
      "input: This is such an amazing product!!! : score: 1.000000\n",
      "input: The product was great!         : score: 1.000000\n",
      "input: The product was meh.           : score: 1.000000\n",
      "input: The product was okish.         : score: 1.000000\n",
      "input: The product was terrible...    : score: 1.000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_my_examples(inputs, results):\n",
    "  result_for_printing = \\\n",
    "    [f'input: {inputs[i]:<30} : score: {results[i][0]:.6f}'\n",
    "                         for i in range(len(inputs))]\n",
    "  print(*result_for_printing, sep='\\n')\n",
    "  print()\n",
    "\n",
    "\n",
    "examples = [\n",
    "    'This is such an amazing product!!!',  # this is the same sentence tried earlier\n",
    "    'The product was great!',\n",
    "    'The product was meh.',\n",
    "    'The product was okish.',\n",
    "    'The product was terrible...'\n",
    "]\n",
    "\n",
    "reloaded_results = tf.sigmoid(reloaded_model(tf.constant(examples)))\n",
    "original_results = tf.sigmoid(classifier_model(tf.constant(examples)))\n",
    "\n",
    "print('Results from the saved model:')\n",
    "print_my_examples(examples, reloaded_results)\n",
    "print('Results from the model in memory:')\n",
    "print_my_examples(examples, original_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
