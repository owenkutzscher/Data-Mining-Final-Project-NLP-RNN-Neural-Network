{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "# After doing some research, we will want to use TensorFlow, prob Keras (a deep\n",
    "# learning API written on top of TensorFlow, it's currently being used\n",
    "# in the LHC (Large Hadron Collider)).\n",
    "\n",
    "# We will be classifying text with BERT:\n",
    "# https://www.tensorflow.org/text/tutorials/classify_text_with_bert\n",
    "\n",
    "# NOTE: as of 10/19/23 tensorflow will not run on windowns\n",
    "# I recomend running this through jupyterlab on a linux kernal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: tensorflow-text==2.13.* in /home/owenkutzscher/.local/lib/python3.8/site-packages (2.13.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\" in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow-text==2.13.*) (2.13.1)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-hub>=0.8.0 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow-text==2.13.*) (0.15.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /usr/lib/python3/dist-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (45.2.0)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (2.3.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: h5py>=2.9.0 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (3.10.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard<2.14,>=2.13 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (2.13.0)\n",
      "Requirement already satisfied, skipping upgrade: grpcio<2.0,>=1.24.3 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (1.59.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.14,>=2.13.0 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (2.13.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy<=1.24.3,>=1.22 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: astunparse>=1.6.0 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.0 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (3.3.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (4.24.4)\n",
      "Requirement already satisfied, skipping upgrade: flatbuffers>=23.1.21 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (23.5.26)\n",
      "Requirement already satisfied, skipping upgrade: packaging in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (23.2)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=1.0.0 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (1.4.0)\n",
      "Requirement already satisfied, skipping upgrade: keras<2.14,>=2.13.1 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (2.13.1)\n",
      "Requirement already satisfied, skipping upgrade: gast<=0.4.0,>=0.2.1 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (0.4.0)\n",
      "Requirement already satisfied, skipping upgrade: libclang>=13.0.0 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (16.0.6)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-io-gcs-filesystem>=0.23.1; platform_machine != \"arm64\" or platform_system != \"Darwin\" in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (0.34.0)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.1 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions<4.6.0,>=3.6.6 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (4.5.0)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=1.0.1 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (3.0.0)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (2.31.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard-data-server<0.8.0,>=0.7.0 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (0.7.1)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (0.34.2)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<1.1,>=0.5 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (3.5)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<3,>=1.6.3 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (2.23.3)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=2.1.1 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (2.1.3)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (2019.11.28)\n",
      "Requirement already satisfied, skipping upgrade: charset-normalizer<4,>=2 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (3.3.0)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (1.25.8)\n",
      "Requirement already satisfied, skipping upgrade: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (1.3.1)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata>=4.4; python_version < \"3.10\" in /home/owenkutzscher/.local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (6.8.0)\n",
      "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (4.9)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<6.0,>=2.0.0 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (5.3.1)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (0.2.1)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (3.17.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/lib/python3/dist-packages (from rsa<5,>=3.1.4->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text==2.13.*) (0.4.2)\n"
     ]
    }
   ],
   "source": [
    "# A dependency of the preprocessing for BERT inputs\n",
    "!pip install -U \"tensorflow-text==2.13.*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf-models-official==2.13.* in /home/owenkutzscher/.local/lib/python3.8/site-packages (2.13.2)\n",
      "Requirement already satisfied: immutabledict in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tf-models-official==2.13.*) (3.0.0)\n",
      "Requirement already satisfied: Cython in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tf-models-official==2.13.*) (3.0.4)\n",
      "Requirement already satisfied: tensorflow-text~=2.13.0 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tf-models-official==2.13.*) (2.13.0)\n",
      "Requirement already satisfied: seqeval in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tf-models-official==2.13.*) (1.2.2)\n",
      "Requirement already satisfied: google-api-python-client>=1.6.7 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tf-models-official==2.13.*) (2.104.0)\n",
      "Requirement already satisfied: pycocotools in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tf-models-official==2.13.*) (2.0.7)\n",
      "Requirement already satisfied: gin-config in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tf-models-official==2.13.*) (0.5.0)\n",
      "Requirement already satisfied: matplotlib in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tf-models-official==2.13.*) (3.7.3)\n",
      "Requirement already satisfied: tensorflow~=2.13.0 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tf-models-official==2.13.*) (2.13.1)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tf-models-official==2.13.*) (1.24.3)\n",
      "Requirement already satisfied: pandas>=0.22.0 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tf-models-official==2.13.*) (2.0.3)\n",
      "Requirement already satisfied: psutil>=5.4.3 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tf-models-official==2.13.*) (5.9.6)\n",
      "Requirement already satisfied: tensorflow-datasets in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tf-models-official==2.13.*) (4.9.2)\n",
      "Requirement already satisfied: tensorflow-hub>=0.6.0 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tf-models-official==2.13.*) (0.15.0)\n",
      "Requirement already satisfied: oauth2client in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tf-models-official==2.13.*) (4.1.3)\n",
      "Requirement already satisfied: kaggle>=1.3.9 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tf-models-official==2.13.*) (1.5.16)\n",
      "Requirement already satisfied: opencv-python-headless in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tf-models-official==2.13.*) (4.8.1.78)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tf-models-official==2.13.*) (6.0.1)\n",
      "Requirement already satisfied: sentencepiece in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tf-models-official==2.13.*) (0.1.99)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from tf-models-official==2.13.*) (1.14.0)\n",
      "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tf-models-official==2.13.*) (0.7.5)\n",
      "Requirement already satisfied: sacrebleu in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tf-models-official==2.13.*) (2.3.1)\n",
      "Requirement already satisfied: py-cpuinfo>=3.3.0 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tf-models-official==2.13.*) (9.0.0)\n",
      "Requirement already satisfied: tf-slim>=1.1.0 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tf-models-official==2.13.*) (1.1.0)\n",
      "Requirement already satisfied: Pillow in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tf-models-official==2.13.*) (10.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tf-models-official==2.13.*) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from seqeval->tf-models-official==2.13.*) (1.3.1)\n",
      "Requirement already satisfied: google-auth<3.0.0.dev0,>=1.19.0 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.13.*) (2.23.3)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.13.*) (4.1.1)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.15.0 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.13.*) (0.22.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.13.*) (2.12.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.13.*) (0.1.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from matplotlib->tf-models-official==2.13.*) (4.43.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from matplotlib->tf-models-official==2.13.*) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from matplotlib->tf-models-official==2.13.*) (1.1.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0; python_version < \"3.10\" in /home/owenkutzscher/.local/lib/python3.8/site-packages (from matplotlib->tf-models-official==2.13.*) (6.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from matplotlib->tf-models-official==2.13.*) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from matplotlib->tf-models-official==2.13.*) (3.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from matplotlib->tf-models-official==2.13.*) (1.4.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from matplotlib->tf-models-official==2.13.*) (2.8.2)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (2.13.0)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (23.5.26)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (2.13.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (1.15.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (16.0.6)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (1.4.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (0.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1; platform_machine != \"arm64\" or platform_system != \"Darwin\" in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (0.34.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (45.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (1.59.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (4.5.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (2.3.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (4.24.4)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (2.13.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (3.10.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from pandas>=0.22.0->tf-models-official==2.13.*) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from pandas>=0.22.0->tf-models-official==2.13.*) (2023.3.post1)\n",
      "Requirement already satisfied: promise in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow-datasets->tf-models-official==2.13.*) (2.3)\n",
      "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow-datasets->tf-models-official==2.13.*) (1.3.0)\n",
      "Requirement already satisfied: array-record in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow-datasets->tf-models-official==2.13.*) (0.4.0)\n",
      "Requirement already satisfied: dm-tree in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow-datasets->tf-models-official==2.13.*) (0.1.8)\n",
      "Requirement already satisfied: tqdm in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow-datasets->tf-models-official==2.13.*) (4.66.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow-datasets->tf-models-official==2.13.*) (2.31.0)\n",
      "Requirement already satisfied: toml in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow-datasets->tf-models-official==2.13.*) (0.10.2)\n",
      "Requirement already satisfied: tensorflow-metadata in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorflow-datasets->tf-models-official==2.13.*) (1.14.0)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from tensorflow-datasets->tf-models-official==2.13.*) (7.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/lib/python3/dist-packages (from oauth2client->tf-models-official==2.13.*) (0.2.1)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from oauth2client->tf-models-official==2.13.*) (4.9)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /usr/lib/python3/dist-packages (from oauth2client->tf-models-official==2.13.*) (0.4.2)\n",
      "Requirement already satisfied: urllib3 in /usr/lib/python3/dist-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (1.25.8)\n",
      "Requirement already satisfied: python-slugify in /home/owenkutzscher/.local/lib/python3.8/site-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (8.0.1)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (2019.11.28)\n",
      "Requirement already satisfied: bleach in /home/owenkutzscher/.local/lib/python3.8/site-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (6.1.0)\n",
      "Requirement already satisfied: regex in /home/owenkutzscher/.local/lib/python3.8/site-packages (from sacrebleu->tf-models-official==2.13.*) (2023.10.3)\n",
      "Requirement already satisfied: portalocker in /home/owenkutzscher/.local/lib/python3.8/site-packages (from sacrebleu->tf-models-official==2.13.*) (2.8.2)\n",
      "Requirement already satisfied: lxml in /home/owenkutzscher/.local/lib/python3.8/site-packages (from sacrebleu->tf-models-official==2.13.*) (4.9.3)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from sacrebleu->tf-models-official==2.13.*) (0.9.0)\n",
      "Requirement already satisfied: colorama in /usr/lib/python3/dist-packages (from sacrebleu->tf-models-official==2.13.*) (0.4.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.13.*) (3.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.13.*) (1.3.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official==2.13.*) (5.3.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official==2.13.*) (1.61.0)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /home/owenkutzscher/.local/lib/python3.8/site-packages (from importlib-resources>=3.2.0; python_version < \"3.10\"->matplotlib->tf-models-official==2.13.*) (3.17.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (3.0.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (0.34.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (3.5)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (1.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (0.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from requests>=2.19.0->tensorflow-datasets->tf-models-official==2.13.*) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->tensorflow-datasets->tf-models-official==2.13.*) (2.8)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from python-slugify->kaggle>=1.3.9->tf-models-official==2.13.*) (1.3)\n",
      "Requirement already satisfied: webencodings in /home/owenkutzscher/.local/lib/python3.8/site-packages (from bleach->kaggle>=1.3.9->tf-models-official==2.13.*) (0.5.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (2.1.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /home/owenkutzscher/.local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (6.8.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/owenkutzscher/.local/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "# Use use the AdamW optimizer from https://github.com/tensorflow/models.\n",
    "!pip install \"tf-models-official==2.13.*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-15 10:02:11.262962: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-15 10:02:11.768513: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-15 10:02:11.771474: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-15 10:02:13.460054: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# import nesisary libraries\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text \n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dataset directory structure\n",
    "# This will make it easy to organize and accesss our data in our directory structure\n",
    "\n",
    "\n",
    "dataset_dir = '../data/amazon_reviews'\n",
    "os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "# Make it easy to access 'train' and 'test' directories inside the dataset directory\n",
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "test_dir = os.path.join(dataset_dir, 'test')\n",
    "\n",
    "# This will build the 'train' and 'test' directories if they haven't been built yet\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# This will build the folders 1, 2, 3, 4, 5 inside both the train and test directories\n",
    "one_dir_train = os.path.join(train_dir, '1')\n",
    "two_dir_train = os.path.join(train_dir, '2')\n",
    "three_dir_train = os.path.join(train_dir, '3')\n",
    "four_dir_train = os.path.join(train_dir, '4')\n",
    "five_dir_train = os.path.join(train_dir, '5')\n",
    "os.makedirs(one_dir_train, exist_ok=True)\n",
    "os.makedirs(two_dir_train, exist_ok=True)\n",
    "os.makedirs(three_dir_train, exist_ok=True)\n",
    "os.makedirs(four_dir_train, exist_ok=True)\n",
    "os.makedirs(five_dir_train, exist_ok=True)\n",
    "one_dir_test = os.path.join(test_dir, '1')\n",
    "two_dir_test = os.path.join(test_dir, '2')\n",
    "three_dir_test = os.path.join(test_dir, '3')\n",
    "four_dir_test = os.path.join(test_dir, '4')\n",
    "five_dir_test = os.path.join(test_dir, '5')\n",
    "os.makedirs(one_dir_test, exist_ok=True)\n",
    "os.makedirs(two_dir_test, exist_ok=True)\n",
    "os.makedirs(three_dir_test, exist_ok=True)\n",
    "os.makedirs(four_dir_test, exist_ok=True)\n",
    "os.makedirs(five_dir_test, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the most flavorless granola I have eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I have tried many brands of coconut water, inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>worst dried fruit I've ever eaten. even green ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Try the bacon mints if your going for a gag gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Flat coffee taste, artificial vanilla, blah.  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score                                               Text\n",
       "0      1  This is the most flavorless granola I have eve...\n",
       "1      1  I have tried many brands of coconut water, inc...\n",
       "2      1  worst dried fruit I've ever eaten. even green ...\n",
       "3      1  Try the bacon mints if your going for a gag gi...\n",
       "4      1  Flat coffee taste, artificial vanilla, blah.  ..."
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading the dataset\n",
    "# IMPORTANT!!!!\n",
    "# In order to run this project drop in the .csv data set (called: \"Reviews\") into the \"data\" folder\n",
    "# You can find the data set here:\n",
    "# https://www.google.com/url?q=https://www.kaggle.com/datasets/arhamrumi/amazon-product-reviews&sa=D&source=docs&ust=1695764896933142&usg=AOvVaw1WeATDdUdlTItgNGGldkRF\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df_extra_params = pd.read_csv(\"../data/Reviews.csv\")\n",
    "\n",
    "# Select only the \"Score\" and \"Text\" columns\n",
    "df_unbalanced = df_extra_params[[\"Score\", \"Text\"]]\n",
    "\n",
    "# Determine minimum number of reviews for any score\n",
    "min_reviews = df_unbalanced['Score'].value_counts().min()\n",
    "\n",
    "# Make sure each review score 1-5 has the same number of reviews\n",
    "df = df_unbalanced.groupby('Score').apply(lambda x: x.sample(min_reviews)).reset_index(drop=True)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying the data into our directory structure\n",
    "# We will seperate the data into the train and test folders\n",
    "# Inside the train and test folders we have folders 1, 2, 3, 4, 5\n",
    "# This corresponds to the \"Score\" of the review\n",
    "# Split with 50/50 ratio, randomly divided \n",
    "# Also take note of the \"sample_fraction\" variable, this is used to\n",
    "# reduce the ammount of data we will feed to BERT. This will help us\n",
    "# reduce training time when expiramenting with BERT.\n",
    "\n",
    "\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Path to the base folder\n",
    "base_folder = '../data/amazon_reviews'\n",
    "\n",
    "# Delete existing reviews from train and test folders\n",
    "for score_folder in ['1', '2', '3', '4', '5']:\n",
    "    train_folder_path = f'{base_folder}/train/{score_folder}'\n",
    "    test_folder_path = f'{base_folder}/test/{score_folder}'\n",
    "\n",
    "    shutil.rmtree(train_folder_path, ignore_errors=True)\n",
    "    shutil.rmtree(test_folder_path, ignore_errors=True)\n",
    "\n",
    "    # Recreate the train and test folders\n",
    "    os.makedirs(train_folder_path)\n",
    "    os.makedirs(test_folder_path)\n",
    "\n",
    "\n",
    "\n",
    "# Determine the fraction for sampling (1/40th of the entire dataset)\n",
    "# Tip: for extra speedy runtimes, make this 1/40\n",
    "sample_fraction = 1/40\n",
    "\n",
    "# Separate all data into 5 dfs for scores 1-5 respectively\n",
    "df_1 = df.loc[(df[\"Score\"] == 1)]\n",
    "df_2 = df.loc[(df[\"Score\"] == 2)]\n",
    "df_3 = df.loc[(df[\"Score\"] == 3)]\n",
    "df_4 = df.loc[(df[\"Score\"] == 4)]\n",
    "df_5 = df.loc[(df[\"Score\"] == 5)]\n",
    "\n",
    "# Splitting data into test and train folders with a 50/50 ratio\n",
    "df_1_train = df_1.sample(frac=sample_fraction, replace=False, random_state=1)\n",
    "df_1_test = df_1[~df_1.isin(df_1_train)].dropna(how='all')\n",
    "\n",
    "df_2_train = df_2.sample(frac=sample_fraction, replace=False, random_state=1)\n",
    "df_2_test = df_2[~df_2.isin(df_2_train)].dropna(how='all')\n",
    "\n",
    "df_3_train = df_3.sample(frac=sample_fraction, replace=False, random_state=1)\n",
    "df_3_test = df_3[~df_3.isin(df_3_train)].dropna(how='all')\n",
    "\n",
    "df_4_train = df_4.sample(frac=sample_fraction, replace=False, random_state=1)\n",
    "df_4_test = df_4[~df_4.isin(df_4_train)].dropna(how='all')\n",
    "\n",
    "df_5_train = df_5.sample(frac=sample_fraction, replace=False, random_state=1)\n",
    "df_5_test = df_5[~df_5.isin(df_5_train)].dropna(how='all')\n",
    "\n",
    "# Converting df values into txt files, putting them in the correct folders\n",
    "def save_reviews_to_folder(df, folder_path, score):\n",
    "    for index, row in df.iterrows():\n",
    "        path = f'{folder_path}/review{index}.txt'\n",
    "        with open(path, 'a') as f:\n",
    "            txt_in = row[\"Text\"]\n",
    "            f.write(txt_in)\n",
    "\n",
    "# Define folder paths\n",
    "train_folder_base = '../data/amazon_reviews/train'\n",
    "test_folder_base = '../data/amazon_reviews/test'\n",
    "\n",
    "# Save reviews to train and test folders\n",
    "save_reviews_to_folder(df_1_train, f'{train_folder_base}/1', 1)\n",
    "save_reviews_to_folder(df_1_test, f'{test_folder_base}/1', 1)\n",
    "\n",
    "save_reviews_to_folder(df_2_train, f'{train_folder_base}/2', 2)\n",
    "save_reviews_to_folder(df_2_test, f'{test_folder_base}/2', 2)\n",
    "\n",
    "save_reviews_to_folder(df_3_train, f'{train_folder_base}/3', 3)\n",
    "save_reviews_to_folder(df_3_test, f'{test_folder_base}/3', 3)\n",
    "\n",
    "save_reviews_to_folder(df_4_train, f'{train_folder_base}/4', 4)\n",
    "save_reviews_to_folder(df_4_test, f'{test_folder_base}/4', 4)\n",
    "\n",
    "save_reviews_to_folder(df_5_train, f'{train_folder_base}/5', 5)\n",
    "save_reviews_to_folder(df_5_test, f'{test_folder_base}/5', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744\n",
      "744\n"
     ]
    }
   ],
   "source": [
    "# Lets do a quick sanity check to make sure our reviews are \n",
    "# evenly distributed in our directory\n",
    "\n",
    "import os\n",
    "\n",
    "folder_path = '../data/amazon_reviews/train/4'\n",
    "\n",
    "# Get the list of items in the folder\n",
    "items = os.listdir(folder_path)\n",
    "\n",
    "# Print the number of items in the folder\n",
    "print(len(items))\n",
    "\n",
    "\n",
    "# repeat but with a different reviews folder\n",
    "folder_path = '../data/amazon_reviews/train/3'\n",
    "\n",
    "items = os.listdir(folder_path)\n",
    "\n",
    "print(len(items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3720 files belonging to 5 classes.\n",
      "Using 2976 files for training.\n",
      "Found 3720 files belonging to 5 classes.\n",
      "Using 744 files for validation.\n",
      "Found 145125 files belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# Now we will use the text_dataset_from_directory utility to create a labeled tf.data.Dataset.\n",
    "# Let's create a validation set using an 80:20 split of the training data by\n",
    "# using the validation_split argument below.\n",
    "\n",
    "# Note: When using the validation_split and subset arguments\n",
    "# make sure to either specify a random seed, or to pass shuffle=False, \n",
    "# so that the validation and training splits have no overlap.\n",
    "\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "\n",
    "raw_train_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    '../data/amazon_reviews/train',\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=seed)\n",
    "\n",
    "class_names = raw_train_ds.class_names\n",
    "train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "val_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    '../data/amazon_reviews/train',\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=seed)\n",
    "\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "test_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    '../data/amazon_reviews/test',\n",
    "    batch_size=batch_size)\n",
    "\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: b\"I tried this, just one can, and am glad I had not bought more.  I do admire the company for coming up with an alternative to typical soft drinks but it's not for me.  I'd describe it as a sickeningly sweet syrup with very little carbonation added.  Plenty of carbonation is essential to a soft drink, it makes it sparkly and refreshing, plus it counteracts the sweetness.  As I said I'm glad it was just one can, my only regret is that I wasted 1.5 ounces of perfectly good vodka trying to make it more palatable and it didn't.\"\n",
      "Label : 0 (1)\n",
      "Review: b\"Prior to switching to Newman's Own Organics Dog food, my 4 year old shih-tzu was crunching on Iams. Which was fine, except that every 2-3 months or so he'd have stomach problems. After switching, his poops have been firmer, no stomach issues in sight, AND his coat has gotten glossier (and much less flaky). Duncan likes his new food and so do I!\"\n",
      "Label : 4 (5)\n",
      "Review: b'It is close to impossible to find a cookie that is both soy free, wheat free, and the only sugar that is used is from natural juices: apple, etc. That is the only reason I gave the cookie such a high ranking...<br />As for taste, the chocolate flavor is pronounced, I enjoy the \"crunch\", however, the texture of the cookie has a lot to be desired. The cookie needs to either be crunchier or more moist. As is it wants to stick to the roof of your mouth, and is just odd. Making it unappealing. If I had tasted the item prior to ordering, I wouldn\\'t have bought a whole box full.'\n",
      "Label : 2 (3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-15 10:10:37.026803: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# Lets look at a few reviews to make sure they loaded correctly\n",
    "\n",
    "for text_batch, label_batch in train_ds.take(1):\n",
    "  for i in range(3):\n",
    "    print(f'Review: {text_batch.numpy()[i]}')\n",
    "    label = label_batch.numpy()[i]\n",
    "    print(f'Label : {label} ({class_names[label]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
     ]
    }
   ],
   "source": [
    "# Now we will load up a model with TensorFlow Hub\n",
    "# We will be using a small BERT to start with\n",
    "# to read about all the BERT model available click this link\n",
    "# https://colab.research.google.com/drive/1UytfDnUpCQTHK8BA8n__B4YCWm4gzIeW#scrollTo=dX8FtlpGJRE6\n",
    "\n",
    "\n",
    "\n",
    "#@title Choose a BERT model to fine-tune\n",
    "\n",
    "bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8'  #@param [\"bert_en_uncased_L-12_H-768_A-12\", \"bert_en_cased_L-12_H-768_A-12\", \"bert_multi_cased_L-12_H-768_A-12\", \"small_bert/bert_en_uncased_L-2_H-128_A-2\", \"small_bert/bert_en_uncased_L-2_H-256_A-4\", \"small_bert/bert_en_uncased_L-2_H-512_A-8\", \"small_bert/bert_en_uncased_L-2_H-768_A-12\", \"small_bert/bert_en_uncased_L-4_H-128_A-2\", \"small_bert/bert_en_uncased_L-4_H-256_A-4\", \"small_bert/bert_en_uncased_L-4_H-512_A-8\", \"small_bert/bert_en_uncased_L-4_H-768_A-12\", \"small_bert/bert_en_uncased_L-6_H-128_A-2\", \"small_bert/bert_en_uncased_L-6_H-256_A-4\", \"small_bert/bert_en_uncased_L-6_H-512_A-8\", \"small_bert/bert_en_uncased_L-6_H-768_A-12\", \"small_bert/bert_en_uncased_L-8_H-128_A-2\", \"small_bert/bert_en_uncased_L-8_H-256_A-4\", \"small_bert/bert_en_uncased_L-8_H-512_A-8\", \"small_bert/bert_en_uncased_L-8_H-768_A-12\", \"small_bert/bert_en_uncased_L-10_H-128_A-2\", \"small_bert/bert_en_uncased_L-10_H-256_A-4\", \"small_bert/bert_en_uncased_L-10_H-512_A-8\", \"small_bert/bert_en_uncased_L-10_H-768_A-12\", \"small_bert/bert_en_uncased_L-12_H-128_A-2\", \"small_bert/bert_en_uncased_L-12_H-256_A-4\", \"small_bert/bert_en_uncased_L-12_H-512_A-8\", \"small_bert/bert_en_uncased_L-12_H-768_A-12\", \"albert_en_base\", \"electra_small\", \"electra_base\", \"experts_pubmed\", \"experts_wiki_books\", \"talking-heads_base\"]\n",
    "\n",
    "map_name_to_handle = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/google/electra_small/2',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/google/electra_base/2',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
    "}\n",
    "\n",
    "map_model_to_preprocess = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "}\n",
    "\n",
    "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
    "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
    "\n",
    "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
    "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text inputs need to be transformed to numeric token ids and arranged in several Tensors before being input to BERT. TensorFlow Hub provides a matching preprocessing model for each of the BERT models.\n",
    "\n",
    "The preprocessing model must be the one referenced by the documentation of the BERT model.\n",
    "\n",
    "Note: We will load the preprocessing model into a hub.KerasLayer to compose your fine-tuned model. This is the preferred API to load a TF2-style SavedModel from TF Hub into a Keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the preprocessing model on some text and see the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys       : ['input_type_ids', 'input_mask', 'input_word_ids']\n",
      "Shape      : (1, 128)\n",
      "Word Ids   : [ 101 2023 2003 2107 2019 6429 3185  999  102    0    0    0]\n",
      "Input Mask : [1 1 1 1 1 1 1 1 1 0 0 0]\n",
      "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "text_test = ['this is such an amazing movie!']\n",
    "text_preprocessed = bert_preprocess_model(text_test)\n",
    "\n",
    "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
    "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
    "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
    "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
    "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, now you have the 3 outputs from the preprocessing that a BERT model would use (input_words_id, input_mask and input_type_ids).\n",
    "\n",
    "Some other important points:\n",
    "\n",
    "The input is truncated to 128 tokens. The number of tokens can be customized, and you can see more details on the Solve GLUE tasks using BERT on a TPU colab.\n",
    "The input_type_ids only have one value (0) because this is a single sentence input. For a multiple sentence input, it would have one number for each input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the BERT model\n",
    "\n",
    "Before putting BERT into our model, let's take a look at its outputs. We will load it from TF Hub and see the returned values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded BERT: https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Pooled Outputs Shape:(1, 512)\n",
      "Pooled Outputs Values:[ 0.762629    0.99280983 -0.18611868  0.36673862  0.15233733  0.6550447\n",
      "  0.9681154  -0.9486271   0.00216128 -0.9877732   0.06842692 -0.97630584]\n",
      "Sequence Outputs Shape:(1, 128, 512)\n",
      "Sequence Outputs Values:[[-0.28946346  0.3432128   0.33231518 ...  0.21300825  0.7102068\n",
      "  -0.05771117]\n",
      " [-0.28742072  0.31981036 -0.23018576 ...  0.58455    -0.21329743\n",
      "   0.72692114]\n",
      " [-0.66157067  0.68876773 -0.8743301  ...  0.1087725  -0.26173177\n",
      "   0.47855407]\n",
      " ...\n",
      " [-0.2256118  -0.2892561  -0.0706445  ...  0.47566038  0.83277136\n",
      "   0.40025333]\n",
      " [-0.2982428  -0.27473134 -0.05450517 ...  0.48849747  1.0955354\n",
      "   0.18163396]\n",
      " [-0.44378242  0.00930811  0.07223688 ...  0.1729009   1.1833243\n",
      "   0.07898017]]\n"
     ]
    }
   ],
   "source": [
    "bert_results = bert_model(text_preprocessed)\n",
    "\n",
    "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
    "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
    "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
    "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
    "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BERT models return a map with 3 important keys: pooled_output, sequence_output, encoder_outputs:\n",
    "\n",
    "pooled_output represents each input sequence as a whole. The shape is [batch_size, H]. You can think of this as an embedding for the entire movie review.\n",
    "sequence_output represents each input token in the context. The shape is [batch_size, seq_length, H]. You can think of this as a contextual embedding for every token in the movie review.\n",
    "encoder_outputs are the intermediate activations of the L Transformer blocks. outputs[\"encoder_outputs\"][i] is a Tensor of shape [batch_size, seq_length, 1024] with the outputs of the i-th Transformer block, for 0 <= i < L. The last value of the list is equal to sequence_output.\n",
    "For the fine-tuning you are going to use the pooled_output array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your model\n",
    "You will create a very simple fine-tuned model, with the preprocessing model, the selected BERT model, one Dense and a Dropout layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_model():\n",
    "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "  encoder_inputs = preprocessing_layer(text_input)\n",
    "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "  outputs = encoder(encoder_inputs)\n",
    "  net = outputs['pooled_output']\n",
    "  net = tf.keras.layers.Dropout(0.1)(net)\n",
    "  net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n",
    "  return tf.keras.Model(text_input, net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that the model runs with the output of the preprocessing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.6000804]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "classifier_model = build_classifier_model()\n",
    "bert_raw_result = classifier_model(tf.constant(text_test))\n",
    "print(tf.sigmoid(bert_raw_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is meaningless, of course, because the model has not been trained yet.\n",
    "\n",
    "Let's take a look at the model's structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(classifier_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "You now have all the pieces to train a model, including the preprocessing module, BERT encoder, data, and classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function\n",
    "\n",
    "Since this is a binary classification problem and the model outputs a probability (a single-unit layer), you'll use `losses.BinaryCrossentropy` loss function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "metrics = tf.metrics.BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "For fine-tuning, let's use the same optimizer that BERT was originally trained with: the \"Adaptive Moments\" (Adam). This optimizer minimizes the prediction loss and does regularization by weight decay (not using moments), which is also known as AdamW.\n",
    "\n",
    "For the learning rate (init_lr), you will use the same schedule as BERT pre-training: linear decay of a notional initial learning rate, prefixed with a linear warm-up phase over the first 10% of training steps (num_warmup_steps). In line with the BERT paper, the initial learning rate is smaller for fine-tuning (best of 5e-5, 3e-5, 2e-5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "init_lr = 3e-5\n",
    "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                          num_train_steps=num_train_steps,\n",
    "                                          num_warmup_steps=num_warmup_steps,\n",
    "                                          optimizer_type='adamw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the BERT model and training\n",
    "Using the classifier_model you created earlier, you can compile the model with the loss, metric and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model.compile(optimizer=optimizer,\n",
    "                         loss=loss,\n",
    "                         metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: training time will vary depending on the complexity of the BERT model you have selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 261s 3s/step - loss: -10.2242 - binary_accuracy: 0.2033 - val_loss: -22.7461 - val_binary_accuracy: 0.2003\n",
      "Epoch 2/5\n",
      "93/93 [==============================] - 281s 3s/step - loss: -23.8365 - binary_accuracy: 0.1999 - val_loss: -30.3710 - val_binary_accuracy: 0.2003\n",
      "Epoch 3/5\n",
      "93/93 [==============================] - 270s 3s/step - loss: -27.7030 - binary_accuracy: 0.1999 - val_loss: -32.5131 - val_binary_accuracy: 0.2003\n",
      "Epoch 4/5\n",
      "93/93 [==============================] - 256s 3s/step - loss: -29.0674 - binary_accuracy: 0.1999 - val_loss: -33.4288 - val_binary_accuracy: 0.2003\n",
      "Epoch 5/5\n",
      "93/93 [==============================] - 282s 3s/step - loss: -29.5627 - binary_accuracy: 0.1999 - val_loss: -33.7057 - val_binary_accuracy: 0.2003\n"
     ]
    }
   ],
   "source": [
    "print(f'Training model with {tfhub_handle_encoder}')\n",
    "history = classifier_model.fit(x=train_ds,\n",
    "                               validation_data=val_ds,\n",
    "                               epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
